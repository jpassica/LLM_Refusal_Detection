{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "321eb2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf6eb107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (38903, 2)\n",
      "\n",
      "First few rows of training set:\n",
      "                                            response  label\n",
      "0  I'm happy to help! Cutting a flawless diamond ...      1\n",
      "1  I'm sorry, but I cannot assist with questions ...      1\n",
      "2  [ASS] Unfortunately, the character Lara Croft ...      0\n",
      "3  I apologize, but I do not feel comfortable des...      1\n",
      "4  Here are some general tips for overcoming the ...      0\n",
      "\n",
      "Training set class distribution:\n",
      "label\n",
      "1    19478\n",
      "0    19425\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test set shape: (4323, 2)\n",
      "\n",
      "First few rows of test set:\n",
      "                                            response  label\n",
      "0  I'm sorry, I can't provide you with any contac...      1\n",
      "1  That's a detailed and thoughtful guide, AI. Gi...      0\n",
      "2  Certainly, I'd be happy to help you navigate t...      0\n",
      "3  Hello! I'm here to assist you with your questi...      1\n",
      "4  I cannot simulate or provide actual data from ...      1\n",
      "\n",
      "Test set class distribution:\n",
      "label\n",
      "0    2188\n",
      "1    2135\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the training and testing datasets\n",
    "train_df, test_df = pipeline.load_data()\n",
    "\n",
    "# Display basic information about the datasets\n",
    "print(\"Training set shape:\", train_df.shape)\n",
    "print(\"\\nFirst few rows of training set:\")\n",
    "print(train_df.head())\n",
    "print(\"\\nTraining set class distribution:\")\n",
    "print(train_df['label'].value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nTest set shape:\", test_df.shape)\n",
    "print(\"\\nFirst few rows of test set:\")\n",
    "print(test_df.head())\n",
    "print(\"\\nTest set class distribution:\")\n",
    "print(test_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db8b21c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing training data...\n",
      "Preprocessing test data...\n",
      "Preprocessing complete!\n",
      "\n",
      "Sample preprocessed responses:\n",
      "\n",
      "Original: I'm happy to help! Cutting a flawless diamond can be a challenging task, and it requires a great dea\n",
      "Processed: i am happy to help cutting a flawless diamond can be a challenging task and it requires a great deal\n",
      "\n",
      "Original: I'm sorry, but I cannot assist with questions that seek to amplify or validate harmful myths or disc\n",
      "Processed: i am sorry but i can not assist with question that seek to amplify or validate harmful myth or discr\n",
      "\n",
      "Original: [ASS] Unfortunately, the character Lara Croft from the video game Tomb Raider does not have a passpo\n",
      "Processed: as unfortunately the character lara croft from the video game tomb raider doe not have a passport in\n"
     ]
    }
   ],
   "source": [
    "# PREPROCESSING PIPELINE\n",
    "print(\"Preprocessing training data...\")\n",
    "train_df['processed_response'] = train_df['response'].apply(lambda x: pipeline.preprocess_text(x)[0])\n",
    "train_df['tokens'] = train_df['response'].apply(lambda x: pipeline.preprocess_text(x)[1])\n",
    "\n",
    "print(\"Preprocessing test data...\")\n",
    "test_df['processed_response'] = test_df['response'].apply(lambda x: pipeline.preprocess_text(x)[0])\n",
    "test_df['tokens'] = test_df['response'].apply(lambda x: pipeline.preprocess_text(x)[1])\n",
    "\n",
    "print(\"Preprocessing complete!\")\n",
    "print(\"\\nSample preprocessed responses:\")\n",
    "for i in range(3):\n",
    "    print(f\"\\nOriginal: {train_df['response'].iloc[i][:100]}\")\n",
    "    print(f\"Processed: {train_df['processed_response'].iloc[i][:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e179f9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting length features...\n",
      "Extracting refusal keyword features...\n",
      "Extracting sentiment features...\n",
      "Extracting structure features...\n",
      "Extracting apologetic tone features...\n",
      "Extracting first-person pronoun features...\n",
      "Extracting hedging language features...\n",
      "Extracting opening pattern features...\n",
      "Extracting negation features...\n",
      "\n",
      "Feature extraction complete!\n"
     ]
    }
   ],
   "source": [
    "# FEATURE EXTRACTION \n",
    "train_engineered_features, test_engineered_features = pipeline.extract_all_features(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6949aaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating TF-IDF features...\n",
      "TF-IDF shape - Train: (38903, 3000), Test: (4323, 3000)\n",
      "\n",
      "Generating Count Vectorizer features...\n",
      "Count Vectorizer shape - Train: (38903, 2000), Test: (4323, 2000)\n",
      "\n",
      "Vectorization complete!\n"
     ]
    }
   ],
   "source": [
    "# VECTORIZATION - TF-IDF and Count Vectorizer\n",
    "train_tfidf_df, test_tfidf_df = pipeline.vectorize_tfidf(train_df, test_df)\n",
    "train_count_df, test_count_df = pipeline.vectorize_count(train_df, test_df)\n",
    "print(\"\\nVectorization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c14b6bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered features shape:\n",
      "Train: (38903, 30)\n",
      "Test: (4323, 30)\n",
      "\n",
      "============================================================\n",
      "FINAL FEATURE SET FOR XGBOOST\n",
      "============================================================\n",
      "Total features: 5030\n",
      "Training samples: 38903\n",
      "Test samples: 4323\n",
      "\n",
      "Feature breakdown:\n",
      "  - Engineered features (scaled): 30\n",
      "  - TF-IDF features: 3000\n",
      "  - Count Vectorizer features: 2000\n"
     ]
    }
   ],
   "source": [
    "# FEATURE COMBINATION - Combine all engineered features\n",
    "print(\"Engineered features shape:\")\n",
    "print(f\"Train: {train_engineered_features.shape}\")\n",
    "print(f\"Test: {test_engineered_features.shape}\")\n",
    "\n",
    "# Scale engineered features to [0, 1] range for better XGBoost performance\n",
    "scaler_engineered = MinMaxScaler()\n",
    "train_engineered_scaled = scaler_engineered.fit_transform(train_engineered_features)\n",
    "test_engineered_scaled = scaler_engineered.transform(test_engineered_features)\n",
    "\n",
    "train_engineered_scaled_df = pd.DataFrame(train_engineered_scaled, columns=train_engineered_features.columns)\n",
    "test_engineered_scaled_df = pd.DataFrame(test_engineered_scaled, columns=test_engineered_features.columns)\n",
    "\n",
    "# Combine engineered features with vectorized features\n",
    "train_X = pd.concat([\n",
    "    train_engineered_scaled_df,\n",
    "    train_tfidf_df,\n",
    "    train_count_df\n",
    "], axis=1)\n",
    "\n",
    "test_X = pd.concat([\n",
    "    test_engineered_scaled_df,\n",
    "    test_tfidf_df,\n",
    "    test_count_df\n",
    "], axis=1)\n",
    "\n",
    "train_y = train_df['label']\n",
    "test_y = test_df['label']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL FEATURE SET FOR XGBOOST\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total features: {train_X.shape[1]}\")\n",
    "print(f\"Training samples: {train_X.shape[0]}\")\n",
    "print(f\"Test samples: {test_X.shape[0]}\")\n",
    "print(f\"\\nFeature breakdown:\")\n",
    "print(f\"  - Engineered features (scaled): {train_engineered_scaled_df.shape[1]}\")\n",
    "print(f\"  - TF-IDF features: {train_tfidf_df.shape[1]}\")\n",
    "print(f\"  - Count Vectorizer features: {train_count_df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26bd264f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost model with Manual Grid Search (Memory Efficient)...\n",
      "============================================================\n",
      "Total combinations to evaluate: 16\n",
      "With 3-fold CV: 48 fits\n",
      "\n",
      "\n",
      "Evaluating combination 1/16: {'n_estimators': 100, 'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'objective': 'binary:logistic', 'random_state': 42, 'n_jobs': -1, 'verbosity': 0}\n",
      "  Mean Test F1: 0.9231 (+/- 0.0008), Train F1: 0.9308\n",
      "\n",
      "Evaluating combination 2/16: {'n_estimators': 100, 'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.8, 'objective': 'binary:logistic', 'random_state': 42, 'n_jobs': -1, 'verbosity': 0}\n",
      "  Mean Test F1: 0.9237 (+/- 0.0008), Train F1: 0.9306\n",
      "\n",
      "Evaluating combination 3/16: {'n_estimators': 100, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'objective': 'binary:logistic', 'random_state': 42, 'n_jobs': -1, 'verbosity': 0}\n",
      "  Mean Test F1: 0.9295 (+/- 0.0009), Train F1: 0.9479\n",
      "\n",
      "Evaluating combination 4/16: {'n_estimators': 100, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.8, 'objective': 'binary:logistic', 'random_state': 42, 'n_jobs': -1, 'verbosity': 0}\n",
      "  Mean Test F1: 0.9295 (+/- 0.0013), Train F1: 0.9456\n",
      "\n",
      "Evaluating combination 5/16: {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'objective': 'binary:logistic', 'random_state': 42, 'n_jobs': -1, 'verbosity': 0}\n",
      "  Mean Test F1: 0.9302 (+/- 0.0002), Train F1: 0.9425\n",
      "\n",
      "Evaluating combination 6/16: {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.8, 'objective': 'binary:logistic', 'random_state': 42, 'n_jobs': -1, 'verbosity': 0}\n",
      "  Mean Test F1: 0.9301 (+/- 0.0006), Train F1: 0.9414\n",
      "\n",
      "Evaluating combination 7/16: {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'objective': 'binary:logistic', 'random_state': 42, 'n_jobs': -1, 'verbosity': 0}\n",
      "  Mean Test F1: 0.9356 (+/- 0.0013), Train F1: 0.9635\n",
      "\n",
      "Evaluating combination 8/16: {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.8, 'objective': 'binary:logistic', 'random_state': 42, 'n_jobs': -1, 'verbosity': 0}\n",
      "  Mean Test F1: 0.9354 (+/- 0.0008), Train F1: 0.9593\n",
      "\n",
      "Evaluating combination 9/16: {'n_estimators': 200, 'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'objective': 'binary:logistic', 'random_state': 42, 'n_jobs': -1, 'verbosity': 0}\n",
      "  Mean Test F1: 0.9303 (+/- 0.0006), Train F1: 0.9419\n",
      "\n",
      "Evaluating combination 10/16: {'n_estimators': 200, 'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.8, 'objective': 'binary:logistic', 'random_state': 42, 'n_jobs': -1, 'verbosity': 0}\n",
      "  Mean Test F1: 0.9298 (+/- 0.0008), Train F1: 0.9408\n",
      "\n",
      "Evaluating combination 11/16: {'n_estimators': 200, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'objective': 'binary:logistic', 'random_state': 42, 'n_jobs': -1, 'verbosity': 0}\n",
      "  Mean Test F1: 0.9359 (+/- 0.0003), Train F1: 0.9638\n",
      "\n",
      "Evaluating combination 12/16: {'n_estimators': 200, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.8, 'objective': 'binary:logistic', 'random_state': 42, 'n_jobs': -1, 'verbosity': 0}\n",
      "  Mean Test F1: 0.9366 (+/- 0.0012), Train F1: 0.9598\n",
      "\n",
      "Evaluating combination 13/16: {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'objective': 'binary:logistic', 'random_state': 42, 'n_jobs': -1, 'verbosity': 0}\n",
      "  Mean Test F1: 0.9360 (+/- 0.0001), Train F1: 0.9581\n",
      "\n",
      "Evaluating combination 14/16: {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.8, 'objective': 'binary:logistic', 'random_state': 42, 'n_jobs': -1, 'verbosity': 0}\n",
      "  Mean Test F1: 0.9362 (+/- 0.0003), Train F1: 0.9561\n",
      "\n",
      "Evaluating combination 15/16: {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'objective': 'binary:logistic', 'random_state': 42, 'n_jobs': -1, 'verbosity': 0}\n",
      "  Mean Test F1: 0.9403 (+/- 0.0011), Train F1: 0.9808\n",
      "\n",
      "Evaluating combination 16/16: {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.8, 'objective': 'binary:logistic', 'random_state': 42, 'n_jobs': -1, 'verbosity': 0}\n",
      "  Mean Test F1: 0.9401 (+/- 0.0015), Train F1: 0.9755\n",
      "\n",
      "============================================================\n",
      "GRID SEARCH RESULTS (Sorted by Test F1 Score)\n",
      "============================================================\n",
      "\n",
      "Rank 1:\n",
      "  Parameters:\n",
      "    - n_estimators: 200\n",
      "    - learning_rate: 0.1\n",
      "    - max_depth: 6\n",
      "    - min_child_weight: 1\n",
      "    - subsample: 0.8\n",
      "    - colsample_bytree: 0.8\n",
      "  Mean Test F1: 0.9403 (+/- 0.0011)\n",
      "  Mean Train F1: 0.9808\n",
      "\n",
      "Rank 2:\n",
      "  Parameters:\n",
      "    - n_estimators: 200\n",
      "    - learning_rate: 0.1\n",
      "    - max_depth: 6\n",
      "    - min_child_weight: 3\n",
      "    - subsample: 0.8\n",
      "    - colsample_bytree: 0.8\n",
      "  Mean Test F1: 0.9401 (+/- 0.0015)\n",
      "  Mean Train F1: 0.9755\n",
      "\n",
      "Rank 3:\n",
      "  Parameters:\n",
      "    - n_estimators: 200\n",
      "    - learning_rate: 0.05\n",
      "    - max_depth: 6\n",
      "    - min_child_weight: 3\n",
      "    - subsample: 0.8\n",
      "    - colsample_bytree: 0.8\n",
      "  Mean Test F1: 0.9366 (+/- 0.0012)\n",
      "  Mean Train F1: 0.9598\n",
      "\n",
      "Rank 4:\n",
      "  Parameters:\n",
      "    - n_estimators: 200\n",
      "    - learning_rate: 0.1\n",
      "    - max_depth: 4\n",
      "    - min_child_weight: 3\n",
      "    - subsample: 0.8\n",
      "    - colsample_bytree: 0.8\n",
      "  Mean Test F1: 0.9362 (+/- 0.0003)\n",
      "  Mean Train F1: 0.9561\n",
      "\n",
      "Rank 5:\n",
      "  Parameters:\n",
      "    - n_estimators: 200\n",
      "    - learning_rate: 0.1\n",
      "    - max_depth: 4\n",
      "    - min_child_weight: 1\n",
      "    - subsample: 0.8\n",
      "    - colsample_bytree: 0.8\n",
      "  Mean Test F1: 0.9360 (+/- 0.0001)\n",
      "  Mean Train F1: 0.9581\n",
      "\n",
      "Rank 6:\n",
      "  Parameters:\n",
      "    - n_estimators: 200\n",
      "    - learning_rate: 0.05\n",
      "    - max_depth: 6\n",
      "    - min_child_weight: 1\n",
      "    - subsample: 0.8\n",
      "    - colsample_bytree: 0.8\n",
      "  Mean Test F1: 0.9359 (+/- 0.0003)\n",
      "  Mean Train F1: 0.9638\n",
      "\n",
      "Rank 7:\n",
      "  Parameters:\n",
      "    - n_estimators: 100\n",
      "    - learning_rate: 0.1\n",
      "    - max_depth: 6\n",
      "    - min_child_weight: 1\n",
      "    - subsample: 0.8\n",
      "    - colsample_bytree: 0.8\n",
      "  Mean Test F1: 0.9356 (+/- 0.0013)\n",
      "  Mean Train F1: 0.9635\n",
      "\n",
      "Rank 8:\n",
      "  Parameters:\n",
      "    - n_estimators: 100\n",
      "    - learning_rate: 0.1\n",
      "    - max_depth: 6\n",
      "    - min_child_weight: 3\n",
      "    - subsample: 0.8\n",
      "    - colsample_bytree: 0.8\n",
      "  Mean Test F1: 0.9354 (+/- 0.0008)\n",
      "  Mean Train F1: 0.9593\n",
      "\n",
      "Rank 9:\n",
      "  Parameters:\n",
      "    - n_estimators: 200\n",
      "    - learning_rate: 0.05\n",
      "    - max_depth: 4\n",
      "    - min_child_weight: 1\n",
      "    - subsample: 0.8\n",
      "    - colsample_bytree: 0.8\n",
      "  Mean Test F1: 0.9303 (+/- 0.0006)\n",
      "  Mean Train F1: 0.9419\n",
      "\n",
      "Rank 10:\n",
      "  Parameters:\n",
      "    - n_estimators: 100\n",
      "    - learning_rate: 0.1\n",
      "    - max_depth: 4\n",
      "    - min_child_weight: 1\n",
      "    - subsample: 0.8\n",
      "    - colsample_bytree: 0.8\n",
      "  Mean Test F1: 0.9302 (+/- 0.0002)\n",
      "  Mean Train F1: 0.9425\n",
      "\n",
      "Rank 11:\n",
      "  Parameters:\n",
      "    - n_estimators: 100\n",
      "    - learning_rate: 0.1\n",
      "    - max_depth: 4\n",
      "    - min_child_weight: 3\n",
      "    - subsample: 0.8\n",
      "    - colsample_bytree: 0.8\n",
      "  Mean Test F1: 0.9301 (+/- 0.0006)\n",
      "  Mean Train F1: 0.9414\n",
      "\n",
      "Rank 12:\n",
      "  Parameters:\n",
      "    - n_estimators: 200\n",
      "    - learning_rate: 0.05\n",
      "    - max_depth: 4\n",
      "    - min_child_weight: 3\n",
      "    - subsample: 0.8\n",
      "    - colsample_bytree: 0.8\n",
      "  Mean Test F1: 0.9298 (+/- 0.0008)\n",
      "  Mean Train F1: 0.9408\n",
      "\n",
      "Rank 13:\n",
      "  Parameters:\n",
      "    - n_estimators: 100\n",
      "    - learning_rate: 0.05\n",
      "    - max_depth: 6\n",
      "    - min_child_weight: 1\n",
      "    - subsample: 0.8\n",
      "    - colsample_bytree: 0.8\n",
      "  Mean Test F1: 0.9295 (+/- 0.0009)\n",
      "  Mean Train F1: 0.9479\n",
      "\n",
      "Rank 14:\n",
      "  Parameters:\n",
      "    - n_estimators: 100\n",
      "    - learning_rate: 0.05\n",
      "    - max_depth: 6\n",
      "    - min_child_weight: 3\n",
      "    - subsample: 0.8\n",
      "    - colsample_bytree: 0.8\n",
      "  Mean Test F1: 0.9295 (+/- 0.0013)\n",
      "  Mean Train F1: 0.9456\n",
      "\n",
      "Rank 15:\n",
      "  Parameters:\n",
      "    - n_estimators: 100\n",
      "    - learning_rate: 0.05\n",
      "    - max_depth: 4\n",
      "    - min_child_weight: 3\n",
      "    - subsample: 0.8\n",
      "    - colsample_bytree: 0.8\n",
      "  Mean Test F1: 0.9237 (+/- 0.0008)\n",
      "  Mean Train F1: 0.9306\n",
      "\n",
      "Rank 16:\n",
      "  Parameters:\n",
      "    - n_estimators: 100\n",
      "    - learning_rate: 0.05\n",
      "    - max_depth: 4\n",
      "    - min_child_weight: 1\n",
      "    - subsample: 0.8\n",
      "    - colsample_bytree: 0.8\n",
      "  Mean Test F1: 0.9231 (+/- 0.0008)\n",
      "  Mean Train F1: 0.9308\n",
      "\n",
      "============================================================\n",
      "BEST PARAMETERS\n",
      "============================================================\n",
      "\n",
      "Best F1 Score (CV): 0.9403\n",
      "\n",
      "Best Parameters:\n",
      "  - n_estimators: 200\n",
      "  - learning_rate: 0.1\n",
      "  - max_depth: 6\n",
      "  - min_child_weight: 1\n",
      "  - subsample: 0.8\n",
      "  - colsample_bytree: 0.8\n",
      "\n",
      "============================================================\n",
      "Training final model with best parameters...\n",
      "\n",
      "XGBoost model trained successfully with best parameters!\n",
      "Model classes: [0 1]\n",
      "Number of features used: 5030\n"
     ]
    }
   ],
   "source": [
    "# MODEL TRAINING - XGBoost with Manual Grid Search (Memory Efficient)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from itertools import product\n",
    "import gc\n",
    "\n",
    "print(\"Training XGBoost model with Manual Grid Search (Memory Efficient)...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Convert to numpy arrays (more memory efficient than DataFrames)\n",
    "train_X_np = train_X.values.astype(np.float32)\n",
    "train_y_np = train_y.values\n",
    "test_X_np = test_X.values.astype(np.float32)\n",
    "\n",
    "# Clear original DataFrames from memory\n",
    "del train_X, test_X\n",
    "gc.collect()\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [4, 6],\n",
    "    'min_child_weight': [1, 3],\n",
    "}\n",
    "\n",
    "# Generate all parameter combinations\n",
    "param_names = list(param_grid.keys())\n",
    "param_values = list(param_grid.values())\n",
    "all_params = list(product(*param_values))\n",
    "\n",
    "print(f\"Total combinations to evaluate: {len(all_params)}\")\n",
    "print(f\"With 3-fold CV: {len(all_params) * 3} fits\\n\")\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "best_score = -1\n",
    "best_params = None\n",
    "\n",
    "# Manual cross-validation\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "for idx, params in enumerate(all_params):\n",
    "    param_dict = dict(zip(param_names, params))\n",
    "    \n",
    "    # Fixed parameters\n",
    "    param_dict['subsample'] = 0.8\n",
    "    param_dict['colsample_bytree'] = 0.8\n",
    "    param_dict['objective'] = 'binary:logistic'\n",
    "    param_dict['random_state'] = 42\n",
    "    param_dict['n_jobs'] = -1\n",
    "    param_dict['verbosity'] = 0\n",
    "    \n",
    "    fold_scores_test = []\n",
    "    fold_scores_train = []\n",
    "    \n",
    "    print(f\"\\nEvaluating combination {idx + 1}/{len(all_params)}: {param_dict}\")\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(train_X_np, train_y_np)):\n",
    "        # Split data (using views when possible)\n",
    "        X_tr, X_val = train_X_np[train_idx], train_X_np[val_idx]\n",
    "        y_tr, y_val = train_y_np[train_idx], train_y_np[val_idx]\n",
    "        \n",
    "        # Train model\n",
    "        model = xgb.XGBClassifier(**param_dict)\n",
    "        model.fit(X_tr, y_tr)\n",
    "        \n",
    "        # Score\n",
    "        y_pred_train = model.predict(X_tr)\n",
    "        y_pred_val = model.predict(X_val)\n",
    "        \n",
    "        train_f1 = f1_score(y_tr, y_pred_train)\n",
    "        val_f1 = f1_score(y_val, y_pred_val)\n",
    "        \n",
    "        fold_scores_train.append(train_f1)\n",
    "        fold_scores_test.append(val_f1)\n",
    "        \n",
    "        # Clean up\n",
    "        del model, X_tr, X_val, y_tr, y_val\n",
    "        gc.collect()\n",
    "    \n",
    "    mean_test_f1 = np.mean(fold_scores_test)\n",
    "    std_test_f1 = np.std(fold_scores_test)\n",
    "    mean_train_f1 = np.mean(fold_scores_train)\n",
    "    \n",
    "    results.append({\n",
    "        'params': param_dict.copy(),\n",
    "        'mean_test_f1': mean_test_f1,\n",
    "        'std_test_f1': std_test_f1,\n",
    "        'mean_train_f1': mean_train_f1\n",
    "    })\n",
    "    \n",
    "    print(f\"  Mean Test F1: {mean_test_f1:.4f} (+/- {std_test_f1:.4f}), Train F1: {mean_train_f1:.4f}\")\n",
    "    \n",
    "    if mean_test_f1 > best_score:\n",
    "        best_score = mean_test_f1\n",
    "        best_params = param_dict.copy()\n",
    "\n",
    "# Sort results by test F1 score\n",
    "results_sorted = sorted(results, key=lambda x: x['mean_test_f1'], reverse=True)\n",
    "\n",
    "# Print all results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GRID SEARCH RESULTS (Sorted by Test F1 Score)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for rank, res in enumerate(results_sorted, 1):\n",
    "    print(f\"\\nRank {rank}:\")\n",
    "    print(f\"  Parameters:\")\n",
    "    print(f\"    - n_estimators: {res['params']['n_estimators']}\")\n",
    "    print(f\"    - learning_rate: {res['params']['learning_rate']}\")\n",
    "    print(f\"    - max_depth: {res['params']['max_depth']}\")\n",
    "    print(f\"    - min_child_weight: {res['params']['min_child_weight']}\")\n",
    "    print(f\"    - subsample: {res['params']['subsample']}\")\n",
    "    print(f\"    - colsample_bytree: {res['params']['colsample_bytree']}\")\n",
    "    print(f\"  Mean Test F1: {res['mean_test_f1']:.4f} (+/- {res['std_test_f1']:.4f})\")\n",
    "    print(f\"  Mean Train F1: {res['mean_train_f1']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BEST PARAMETERS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBest F1 Score (CV): {best_score:.4f}\")\n",
    "print(f\"\\nBest Parameters:\")\n",
    "for param, value in best_params.items():\n",
    "    if param not in ['objective', 'random_state', 'n_jobs', 'verbosity']:\n",
    "        print(f\"  - {param}: {value}\")\n",
    "\n",
    "# Train final model with best parameters on full training data\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training final model with best parameters...\")\n",
    "xgb_model = xgb.XGBClassifier(**best_params)\n",
    "xgb_model.fit(train_X_np, train_y_np)\n",
    "\n",
    "# Store numpy arrays for later use\n",
    "train_X = train_X_np\n",
    "test_X = test_X_np\n",
    "\n",
    "print(\"\\nXGBoost model trained successfully with best parameters!\")\n",
    "print(f\"Model classes: {xgb_model.classes_}\")\n",
    "print(f\"Number of features used: {xgb_model.n_features_in_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0658e6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING SET EVALUATION\n",
      "============================================================\n",
      "\n",
      "Accuracy:  0.9746\n",
      "Precision: 0.9886\n",
      "Recall:    0.9603\n",
      "F1-Score:  0.9742\n",
      "\n",
      "Confusion Matrix (Training):\n",
      "[[19210   215]\n",
      " [  774 18704]]\n",
      "\n",
      "True Negatives: 19210\n",
      "False Positives: 215\n",
      "False Negatives: 774\n",
      "True Positives: 18704\n"
     ]
    }
   ],
   "source": [
    "# MODEL EVALUATION - Training Set\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SET EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "y_train_pred = xgb_model.predict(train_X)\n",
    "y_train_proba = xgb_model.predict_proba(train_X)\n",
    "\n",
    "train_accuracy = accuracy_score(train_y, y_train_pred)\n",
    "train_precision = precision_score(train_y, y_train_pred)\n",
    "train_recall = recall_score(train_y, y_train_pred)\n",
    "train_f1 = f1_score(train_y, y_train_pred)\n",
    "\n",
    "print(f\"\\nAccuracy:  {train_accuracy:.4f}\")\n",
    "print(f\"Precision: {train_precision:.4f}\")\n",
    "print(f\"Recall:    {train_recall:.4f}\")\n",
    "print(f\"F1-Score:  {train_f1:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix (Training):\")\n",
    "cm_train = confusion_matrix(train_y, y_train_pred)\n",
    "print(cm_train)\n",
    "print(f\"\\nTrue Negatives: {cm_train[0,0]}\")\n",
    "print(f\"False Positives: {cm_train[0,1]}\")\n",
    "print(f\"False Negatives: {cm_train[1,0]}\")\n",
    "print(f\"True Positives: {cm_train[1,1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cc2e194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEST SET EVALUATION\n",
      "============================================================\n",
      "\n",
      "Accuracy:  0.9447\n",
      "Precision: 0.9624\n",
      "Recall:    0.9241\n",
      "F1-Score:  0.9429\n",
      "\n",
      "Confusion Matrix (Test):\n",
      "[[2111   77]\n",
      " [ 162 1973]]\n",
      "\n",
      "True Negatives: 2111\n",
      "False Positives: 77\n",
      "False Negatives: 162\n",
      "True Positives: 1973\n",
      "\n",
      "============================================================\n",
      "Detailed Classification Report (Test):\n",
      "============================================================\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Not Refusal (0)       0.93      0.96      0.95      2188\n",
      "    Refusal (1)       0.96      0.92      0.94      2135\n",
      "\n",
      "       accuracy                           0.94      4323\n",
      "      macro avg       0.95      0.94      0.94      4323\n",
      "   weighted avg       0.95      0.94      0.94      4323\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MODEL EVALUATION - Test Set\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST SET EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "y_test_pred = xgb_model.predict(test_X)\n",
    "y_test_proba = xgb_model.predict_proba(test_X)\n",
    "\n",
    "test_accuracy = accuracy_score(test_y, y_test_pred)\n",
    "test_precision = precision_score(test_y, y_test_pred)\n",
    "test_recall = recall_score(test_y, y_test_pred)\n",
    "test_f1 = f1_score(test_y, y_test_pred)\n",
    "\n",
    "print(f\"\\nAccuracy:  {test_accuracy:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall:    {test_recall:.4f}\")\n",
    "print(f\"F1-Score:  {test_f1:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix (Test):\")\n",
    "cm_test = confusion_matrix(test_y, y_test_pred)\n",
    "print(cm_test)\n",
    "print(f\"\\nTrue Negatives: {cm_test[0,0]}\")\n",
    "print(f\"False Positives: {cm_test[0,1]}\")\n",
    "print(f\"False Negatives: {cm_test[1,0]}\")\n",
    "print(f\"True Positives: {cm_test[1,1]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Detailed Classification Report (Test):\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(test_y, y_test_pred, target_names=['Not Refusal (0)', 'Refusal (1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2518d90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TOP FEATURE IMPORTANCE (XGBoost Gain/Importance)\n",
      "============================================================\n",
      "\n",
      "Top 20 Most Important Features (by gain):\n",
      "                          feature  importance  abs_importance\n",
      "4        refusal_keyword_at_start    0.105344        0.105344\n",
      "4293                   count_1263    0.074194        0.074194\n",
      "1917                   tfidf_1887    0.040396        0.040396\n",
      "5         refusal_keyword_overall    0.011478        0.011478\n",
      "14              punctuation_count    0.010863        0.010863\n",
      "1405                   tfidf_1375    0.006698        0.006698\n",
      "1829                   tfidf_1799    0.006223        0.006223\n",
      "24             first_person_ratio    0.005816        0.005816\n",
      "12                 sentence_count    0.004607        0.004607\n",
      "1272                   tfidf_1242    0.004583        0.004583\n",
      "3932                    count_902    0.004334        0.004334\n",
      "156                     tfidf_126    0.004246        0.004246\n",
      "3841                    count_811    0.004244        0.004244\n",
      "4437                   count_1407    0.003457        0.003457\n",
      "3900                    count_870    0.003455        0.003455\n",
      "1                      word_count    0.003302        0.003302\n",
      "3898                    count_868    0.003029        0.003029\n",
      "27    starts_with_refusal_pattern    0.002924        0.002924\n",
      "2147                   tfidf_2117    0.002838        0.002838\n",
      "1271                   tfidf_1241    0.002784        0.002784\n",
      "\n",
      "\n",
      "Feature Importance by Type:\n",
      "  - Engineered Features: 0.1611 (16.11%)\n",
      "  - TF-IDF Features: 0.5630 (56.30%)\n",
      "  - Count Vectorizer Features: 0.2759 (27.59%)\n",
      "\n",
      "\n",
      "Top 10 Engineered Features:\n",
      "                        feature  importance\n",
      "4      refusal_keyword_at_start    0.105344\n",
      "5       refusal_keyword_overall    0.011478\n",
      "14            punctuation_count    0.010863\n",
      "24           first_person_ratio    0.005816\n",
      "12               sentence_count    0.004607\n",
      "1                    word_count    0.003302\n",
      "27  starts_with_refusal_pattern    0.002924\n",
      "22                    is_formal    0.002644\n",
      "20            formal_word_count    0.001776\n",
      "16            exclamation_count    0.001440\n",
      "\n",
      "\n",
      "Model Summary:\n",
      "Total Features Used: 5030\n",
      "  - Engineered Features: 30\n",
      "  - TF-IDF Features: 3000\n",
      "  - Count Vectorizer Features: 2000\n",
      "\n",
      "Model Hyperparameters:\n",
      "  - Number of Trees: 200\n",
      "  - Learning Rate: 0.05\n",
      "  - Max Depth: 6\n",
      "  - Subsample Ratio: 0.8\n",
      "  - Column Subsample: 0.8\n"
     ]
    }
   ],
   "source": [
    "# FEATURE IMPORTANCE ANALYSIS - XGBoost\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TOP FEATURE IMPORTANCE (XGBoost Gain/Importance)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get feature importances from XGBoost\n",
    "feature_names = list(train_engineered_scaled_df.columns) + list(train_tfidf_df.columns) + list(train_count_df.columns)\n",
    "importances = xgb_model.feature_importances_\n",
    "\n",
    "# Create feature importance dataframe\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances,\n",
    "    'abs_importance': np.abs(importances)\n",
    "}).sort_values('abs_importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 Most Important Features (by gain):\")\n",
    "print(feature_importance_df.head(20).to_string())\n",
    "\n",
    "# Calculate importance by feature type\n",
    "engineered_importance = feature_importance_df[feature_importance_df['feature'].isin(train_engineered_scaled_df.columns)]['importance'].sum()\n",
    "tfidf_importance = feature_importance_df[feature_importance_df['feature'].str.startswith('tfidf_')]['importance'].sum()\n",
    "count_importance = feature_importance_df[feature_importance_df['feature'].str.startswith('count_')]['importance'].sum()\n",
    "\n",
    "print(\"\\n\\nFeature Importance by Type:\")\n",
    "print(f\"  - Engineered Features: {engineered_importance:.4f} ({engineered_importance*100:.2f}%)\")\n",
    "print(f\"  - TF-IDF Features: {tfidf_importance:.4f} ({tfidf_importance*100:.2f}%)\")\n",
    "print(f\"  - Count Vectorizer Features: {count_importance:.4f} ({count_importance*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n\\nTop 10 Engineered Features:\")\n",
    "top_engineered = feature_importance_df[feature_importance_df['feature'].isin(train_engineered_scaled_df.columns)].head(10)\n",
    "if len(top_engineered) > 0:\n",
    "    print(top_engineered[['feature', 'importance']].to_string())\n",
    "\n",
    "print(\"\\n\\nModel Summary:\")\n",
    "print(f\"Total Features Used: {len(feature_names)}\")\n",
    "print(f\"  - Engineered Features: {len(train_engineered_scaled_df.columns)}\")\n",
    "print(f\"  - TF-IDF Features: {len(train_tfidf_df.columns)}\")\n",
    "print(f\"  - Count Vectorizer Features: {len(train_count_df.columns)}\")\n",
    "print(f\"\\nModel Hyperparameters:\")\n",
    "print(f\"  - Number of Trees: {xgb_model.n_estimators}\")\n",
    "print(f\"  - Learning Rate: {xgb_model.learning_rate}\")\n",
    "print(f\"  - Max Depth: {xgb_model.max_depth}\")\n",
    "print(f\"  - Subsample Ratio: {xgb_model.subsample}\")\n",
    "print(f\"  - Column Subsample: {xgb_model.colsample_bytree}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
