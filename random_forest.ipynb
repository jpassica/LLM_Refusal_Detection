{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85075a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee3390b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (38903, 2)\n",
      "\n",
      "First few rows of training set:\n",
      "                                            response  label\n",
      "0  I'm happy to help! Cutting a flawless diamond ...      1\n",
      "1  I'm sorry, but I cannot assist with questions ...      1\n",
      "2  [ASS] Unfortunately, the character Lara Croft ...      0\n",
      "3  I apologize, but I do not feel comfortable des...      1\n",
      "4  Here are some general tips for overcoming the ...      0\n",
      "\n",
      "Training set class distribution:\n",
      "label\n",
      "1    19478\n",
      "0    19425\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test set shape: (4323, 2)\n",
      "\n",
      "First few rows of test set:\n",
      "                                            response  label\n",
      "0  I'm sorry, I can't provide you with any contac...      1\n",
      "1  That's a detailed and thoughtful guide, AI. Gi...      0\n",
      "2  Certainly, I'd be happy to help you navigate t...      0\n",
      "3  Hello! I'm here to assist you with your questi...      1\n",
      "4  I cannot simulate or provide actual data from ...      1\n",
      "\n",
      "Test set class distribution:\n",
      "label\n",
      "0    2188\n",
      "1    2135\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the training and testing datasets\n",
    "train_df, test_df = pipeline.load_data()\n",
    "\n",
    "# Display basic information about the datasets\n",
    "print(\"Training set shape:\", train_df.shape)\n",
    "print(\"\\nFirst few rows of training set:\")\n",
    "print(train_df.head())\n",
    "print(\"\\nTraining set class distribution:\")\n",
    "print(train_df['label'].value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nTest set shape:\", test_df.shape)\n",
    "print(\"\\nFirst few rows of test set:\")\n",
    "print(test_df.head())\n",
    "print(\"\\nTest set class distribution:\")\n",
    "print(test_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e2f602d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing training data...\n",
      "Preprocessing test data...\n",
      "Preprocessing complete!\n",
      "\n",
      "Sample preprocessed responses:\n",
      "\n",
      "Original: I'm happy to help! Cutting a flawless diamond can be a challenging task, and it requires a great dea\n",
      "Processed: i 'm happy to help cutting a flawless diamond can be a challenging task and it requires a great deal\n",
      "\n",
      "Original: I'm sorry, but I cannot assist with questions that seek to amplify or validate harmful myths or disc\n",
      "Processed: i 'm sorry but i can not assist with question that seek to amplify or validate harmful myth or discr\n",
      "\n",
      "Original: [ASS] Unfortunately, the character Lara Croft from the video game Tomb Raider does not have a passpo\n",
      "Processed: as unfortunately the character lara croft from the video game tomb raider doe not have a passport in\n"
     ]
    }
   ],
   "source": [
    "# PREPROCESSING PIPELINE\n",
    "print(\"Preprocessing training data...\")\n",
    "train_df['processed_response'] = train_df['response'].apply(lambda x: pipeline.preprocess_text(x)[0])\n",
    "train_df['tokens'] = train_df['response'].apply(lambda x: pipeline.preprocess_text(x)[1])\n",
    "\n",
    "print(\"Preprocessing test data...\")\n",
    "test_df['processed_response'] = test_df['response'].apply(lambda x: pipeline.preprocess_text(x)[0])\n",
    "test_df['tokens'] = test_df['response'].apply(lambda x: pipeline.preprocess_text(x)[1])\n",
    "\n",
    "print(\"Preprocessing complete!\")\n",
    "print(\"\\nSample preprocessed responses:\")\n",
    "for i in range(3):\n",
    "    print(f\"\\nOriginal: {train_df['response'].iloc[i][:100]}\")\n",
    "    print(f\"Processed: {train_df['processed_response'].iloc[i][:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e48e9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting length features...\n",
      "Extracting refusal keyword features...\n",
      "Extracting sentiment features...\n",
      "Extracting structure features...\n",
      "Extracting apologetic tone features...\n",
      "\n",
      "Feature extraction complete!\n"
     ]
    }
   ],
   "source": [
    "# FEATURE EXTRACTION \n",
    "train_engineered_features, test_engineered_features = pipeline.extract_all_features(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e11bca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating TF-IDF features...\n",
      "TF-IDF shape - Train: (38903, 3000), Test: (4323, 3000)\n",
      "\n",
      "Generating Count Vectorizer features...\n",
      "Count Vectorizer shape - Train: (38903, 2000), Test: (4323, 2000)\n",
      "\n",
      "Vectorization complete!\n"
     ]
    }
   ],
   "source": [
    "# VECTORIZATION - TF-IDF and Count Vectorizer\n",
    "train_tfidf_df, test_tfidf_df = pipeline.vectorize_tfidf(train_df, test_df)\n",
    "train_count_df, test_count_df = pipeline.vectorize_count(train_df, test_df)\n",
    "print(\"\\nVectorization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ddbc011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered features shape:\n",
      "Train: (38903, 23)\n",
      "Test: (4323, 23)\n",
      "\n",
      "Engineered features:\n",
      "['response_length', 'word_count', 'avg_word_length', 'char_per_word', 'refusal_keyword_at_start', 'refusal_keyword_overall', 'has_any_refusal_keyword', 'sentiment_polarity', 'sentiment_subjectivity', 'is_negative_sentiment', 'is_neutral_sentiment', 'is_positive_sentiment', 'sentence_count', 'avg_sentence_length', 'punctuation_count', 'question_mark_count', 'exclamation_count', 'uppercase_ratio', 'has_multiple_sentences', 'apology_word_count', 'formal_word_count', 'is_apologetic', 'is_formal']\n",
      "\n",
      "============================================================\n",
      "FINAL FEATURE SET FOR RANDOM FOREST\n",
      "============================================================\n",
      "Total features: 5023\n",
      "Training samples: 38903\n",
      "Test samples: 4323\n",
      "\n",
      "Feature breakdown:\n",
      "  - Engineered features (scaled): 23\n",
      "  - TF-IDF features: 3000\n",
      "  - Count Vectorizer features: 2000\n",
      "\n",
      "Note: Random Forest does not require feature normalization/scaling\n"
     ]
    }
   ],
   "source": [
    "# FEATURE COMBINATION - Combine all engineered features\n",
    "print(\"Engineered features shape:\")\n",
    "print(f\"Train: {train_engineered_features.shape}\")\n",
    "print(f\"Test: {test_engineered_features.shape}\")\n",
    "\n",
    "# Display engineered feature names\n",
    "print(\"\\nEngineered features:\")\n",
    "print(train_engineered_features.columns.tolist())\n",
    "\n",
    "# Scale engineered features to [0, 1] range for better tree-based model performance\n",
    "scaler_engineered = MinMaxScaler()\n",
    "train_engineered_scaled = scaler_engineered.fit_transform(train_engineered_features)\n",
    "test_engineered_scaled = scaler_engineered.transform(test_engineered_features)\n",
    "\n",
    "train_engineered_scaled_df = pd.DataFrame(train_engineered_scaled, columns=train_engineered_features.columns)\n",
    "test_engineered_scaled_df = pd.DataFrame(test_engineered_scaled, columns=test_engineered_features.columns)\n",
    "\n",
    "# For Random Forest, we can combine TF-IDF and Count Vectorizer with engineered features\n",
    "# Random Forest trees handle different feature scales naturally\n",
    "train_X = pd.concat([\n",
    "    train_engineered_scaled_df,\n",
    "    train_tfidf_df,\n",
    "    train_count_df\n",
    "], axis=1)\n",
    "\n",
    "test_X = pd.concat([\n",
    "    test_engineered_scaled_df,\n",
    "    test_tfidf_df,\n",
    "    test_count_df\n",
    "], axis=1)\n",
    "\n",
    "train_y = train_df['label']\n",
    "test_y = test_df['label']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL FEATURE SET FOR RANDOM FOREST\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total features: {train_X.shape[1]}\")\n",
    "print(f\"Training samples: {train_X.shape[0]}\")\n",
    "print(f\"Test samples: {test_X.shape[0]}\")\n",
    "print(f\"\\nFeature breakdown:\")\n",
    "print(f\"  - Engineered features (scaled): {train_engineered_scaled_df.shape[1]}\")\n",
    "print(f\"  - TF-IDF features: {train_tfidf_df.shape[1]}\")\n",
    "print(f\"  - Count Vectorizer features: {train_count_df.shape[1]}\")\n",
    "print(f\"\\nNote: Random Forest does not require feature normalization/scaling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e735e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest Classifier...\n",
      "Using Random Forest with optimized hyperparameters for text classification\n",
      "Random Forest model trained successfully!\n",
      "Model classes: [0 1]\n",
      "Number of features used: 5023\n",
      "Number of trees: 100\n"
     ]
    }
   ],
   "source": [
    "# MODEL TRAINING - Random Forest Classifier\n",
    "\n",
    "print(\"Training Random Forest Classifier...\")\n",
    "print(\"Using Random Forest with optimized hyperparameters for text classification\")\n",
    "\n",
    "# Random Forest classifier with optimized parameters\n",
    "random_forest_model = RandomForestClassifier(\n",
    "    n_estimators=100,           # Number of trees\n",
    "    max_depth=30,               # Maximum depth of trees\n",
    "    min_samples_split=10,       # Minimum samples to split a node\n",
    "    min_samples_leaf=5,         # Minimum samples at leaf\n",
    "    max_features='sqrt',        # Number of features to consider per split\n",
    "    n_jobs=-1,                  # Use all CPU cores\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "random_forest_model.fit(train_X, train_y)\n",
    "\n",
    "print(\"Random Forest model trained successfully!\")\n",
    "print(f\"Model classes: {random_forest_model.classes_}\")\n",
    "print(f\"Number of features used: {random_forest_model.n_features_in_}\")\n",
    "print(f\"Number of trees: {len(random_forest_model.estimators_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "453c5d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING SET EVALUATION\n",
      "============================================================\n",
      "\n",
      "Accuracy:  0.9551\n",
      "Precision: 0.9843\n",
      "Recall:    0.9251\n",
      "F1-Score:  0.9538\n",
      "\n",
      "Confusion Matrix (Training):\n",
      "[[19138   287]\n",
      " [ 1458 18020]]\n",
      "\n",
      "True Negatives: 19138\n",
      "False Positives: 287\n",
      "False Negatives: 1458\n",
      "True Positives: 18020\n"
     ]
    }
   ],
   "source": [
    "# MODEL EVALUATION - Training Set\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SET EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "y_train_pred = random_forest_model.predict(train_X)\n",
    "y_train_proba = random_forest_model.predict_proba(train_X)\n",
    "\n",
    "train_accuracy = accuracy_score(train_y, y_train_pred)\n",
    "train_precision = precision_score(train_y, y_train_pred)\n",
    "train_recall = recall_score(train_y, y_train_pred)\n",
    "train_f1 = f1_score(train_y, y_train_pred)\n",
    "\n",
    "print(f\"\\nAccuracy:  {train_accuracy:.4f}\")\n",
    "print(f\"Precision: {train_precision:.4f}\")\n",
    "print(f\"Recall:    {train_recall:.4f}\")\n",
    "print(f\"F1-Score:  {train_f1:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix (Training):\")\n",
    "cm_train = confusion_matrix(train_y, y_train_pred)\n",
    "print(cm_train)\n",
    "print(f\"\\nTrue Negatives: {cm_train[0,0]}\")\n",
    "print(f\"False Positives: {cm_train[0,1]}\")\n",
    "print(f\"False Negatives: {cm_train[1,0]}\")\n",
    "print(f\"True Positives: {cm_train[1,1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2073e3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEST SET EVALUATION\n",
      "============================================================\n",
      "\n",
      "Accuracy:  0.9297\n",
      "Precision: 0.9645\n",
      "Recall:    0.8904\n",
      "F1-Score:  0.9260\n",
      "\n",
      "Confusion Matrix (Test):\n",
      "[[2118   70]\n",
      " [ 234 1901]]\n",
      "\n",
      "True Negatives: 2118\n",
      "False Positives: 70\n",
      "False Negatives: 234\n",
      "True Positives: 1901\n",
      "\n",
      "============================================================\n",
      "Detailed Classification Report (Test):\n",
      "============================================================\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Not Refusal (0)       0.90      0.97      0.93      2188\n",
      "    Refusal (1)       0.96      0.89      0.93      2135\n",
      "\n",
      "       accuracy                           0.93      4323\n",
      "      macro avg       0.93      0.93      0.93      4323\n",
      "   weighted avg       0.93      0.93      0.93      4323\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MODEL EVALUATION - Test Set\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST SET EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "y_test_pred = random_forest_model.predict(test_X)\n",
    "y_test_proba = random_forest_model.predict_proba(test_X)\n",
    "\n",
    "test_accuracy = accuracy_score(test_y, y_test_pred)\n",
    "test_precision = precision_score(test_y, y_test_pred)\n",
    "test_recall = recall_score(test_y, y_test_pred)\n",
    "test_f1 = f1_score(test_y, y_test_pred)\n",
    "\n",
    "print(f\"\\nAccuracy:  {test_accuracy:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall:    {test_recall:.4f}\")\n",
    "print(f\"F1-Score:  {test_f1:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix (Test):\")\n",
    "cm_test = confusion_matrix(test_y, y_test_pred)\n",
    "print(cm_test)\n",
    "print(f\"\\nTrue Negatives: {cm_test[0,0]}\")\n",
    "print(f\"False Positives: {cm_test[0,1]}\")\n",
    "print(f\"False Negatives: {cm_test[1,0]}\")\n",
    "print(f\"True Positives: {cm_test[1,1]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Detailed Classification Report (Test):\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(test_y, y_test_pred, target_names=['Not Refusal (0)', 'Refusal (1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80e9b6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TOP FEATURE IMPORTANCE (Random Forest Feature Importances)\n",
      "============================================================\n",
      "\n",
      "Top 30 Most Important Features:\n",
      "                       feature  importance\n",
      "5      refusal_keyword_overall    0.040656\n",
      "4     refusal_keyword_at_start    0.031940\n",
      "14           punctuation_count    0.027911\n",
      "12              sentence_count    0.026360\n",
      "1                   word_count    0.025414\n",
      "6      has_any_refusal_keyword    0.024025\n",
      "442                  tfidf_419    0.023122\n",
      "0              response_length    0.020876\n",
      "1702                tfidf_1679    0.019113\n",
      "3298                 count_275    0.016108\n",
      "3843                 count_820    0.014585\n",
      "1995                tfidf_1972    0.013970\n",
      "3832                 count_809    0.013935\n",
      "20           formal_word_count    0.013112\n",
      "3668                 count_645    0.013009\n",
      "4745                count_1722    0.011629\n",
      "1261                tfidf_1238    0.010926\n",
      "1260                tfidf_1237    0.010387\n",
      "431                  tfidf_408    0.009935\n",
      "22                   is_formal    0.009713\n",
      "3829                 count_806    0.009143\n",
      "3282                 count_259    0.007902\n",
      "1346                tfidf_1323    0.007794\n",
      "3749                 count_726    0.007588\n",
      "419                  tfidf_396    0.007414\n",
      "4179                count_1156    0.006994\n",
      "4142                count_1119    0.006819\n",
      "4149                count_1126    0.006818\n",
      "1795                tfidf_1772    0.006800\n",
      "4878                count_1855    0.006147\n",
      "\n",
      "============================================================\n",
      "Feature Importance by Category:\n",
      "============================================================\n",
      "Engineered Features:     0.2071 (20.71%)\n",
      "TF-IDF Features:         0.4526 (45.26%)\n",
      "Count Vectorizer Features: 0.3109 (31.09%)\n",
      "\n",
      "============================================================\n",
      "Top Engineered Features:\n",
      "============================================================\n",
      "                     feature  importance\n",
      "5    refusal_keyword_overall    0.040656\n",
      "4   refusal_keyword_at_start    0.031940\n",
      "14         punctuation_count    0.027911\n",
      "12            sentence_count    0.026360\n",
      "6    has_any_refusal_keyword    0.024025\n",
      "0            response_length    0.020876\n",
      "20         formal_word_count    0.013112\n",
      "22                 is_formal    0.009713\n",
      "19        apology_word_count    0.003169\n",
      "17           uppercase_ratio    0.002518\n",
      "21             is_apologetic    0.001900\n",
      "8     sentiment_subjectivity    0.001441\n",
      "7         sentiment_polarity    0.001336\n",
      "16         exclamation_count    0.000849\n",
      "18    has_multiple_sentences    0.000434\n",
      "\n",
      "============================================================\n",
      "Model Summary:\n",
      "============================================================\n",
      "Total Features Used: 5023\n",
      "  - Engineered Features: 23\n",
      "  - TF-IDF Features: 3000\n",
      "  - Count Vectorizer Features: 2000\n",
      "\n",
      "Model Hyperparameters:\n",
      "  - Number of Trees: 100\n",
      "  - Max Depth: 30\n",
      "  - Min Samples Split: 10\n",
      "  - Min Samples Leaf: 5\n",
      "  - Max Features: sqrt\n"
     ]
    }
   ],
   "source": [
    "# FEATURE IMPORTANCE ANALYSIS - Random Forest Feature Importances\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TOP FEATURE IMPORTANCE (Random Forest Feature Importances)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get feature importances from Random Forest\n",
    "feature_names = list(train_engineered_scaled_df.columns) + list(train_tfidf_df.columns) + list(train_count_df.columns)\n",
    "importances = random_forest_model.feature_importances_\n",
    "\n",
    "# Create feature importance dataframe\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 30 Most Important Features:\")\n",
    "print(feature_importance_df.head(30).to_string())\n",
    "\n",
    "# Analyze engineered vs vectorized features\n",
    "engineered_importance = feature_importance_df[feature_importance_df['feature'].str.contains(\n",
    "    '^(response_|refusal_|sentiment_|is_|sentence_|punctuation_|question_|exclamation_|uppercase_|has_|apology_|formal_)', \n",
    "    regex=True)]['importance'].sum()\n",
    "\n",
    "tfidf_importance = feature_importance_df[feature_importance_df['feature'].str.startswith('tfidf_')]['importance'].sum()\n",
    "\n",
    "count_importance = feature_importance_df[feature_importance_df['feature'].str.startswith('count_')]['importance'].sum()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Feature Importance by Category:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Engineered Features:     {engineered_importance:.4f} ({engineered_importance*100:.2f}%)\")\n",
    "print(f\"TF-IDF Features:         {tfidf_importance:.4f} ({tfidf_importance*100:.2f}%)\")\n",
    "print(f\"Count Vectorizer Features: {count_importance:.4f} ({count_importance*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Top Engineered Features:\")\n",
    "print(\"=\"*60)\n",
    "top_engineered = feature_importance_df[feature_importance_df['feature'].str.contains(\n",
    "    '^(response_|refusal_|sentiment_|is_|sentence_|punctuation_|question_|exclamation_|uppercase_|has_|apology_|formal_)', \n",
    "    regex=True)].head(15)\n",
    "print(top_engineered.to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Model Summary:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total Features Used: {len(feature_names)}\")\n",
    "print(f\"  - Engineered Features: {len(train_engineered_scaled_df.columns)}\")\n",
    "print(f\"  - TF-IDF Features: {len(train_tfidf_df.columns)}\")\n",
    "print(f\"  - Count Vectorizer Features: {len(train_count_df.columns)}\")\n",
    "print(f\"\\nModel Hyperparameters:\")\n",
    "print(f\"  - Number of Trees: {random_forest_model.n_estimators}\")\n",
    "print(f\"  - Max Depth: {random_forest_model.max_depth}\")\n",
    "print(f\"  - Min Samples Split: {random_forest_model.min_samples_split}\")\n",
    "print(f\"  - Min Samples Leaf: {random_forest_model.min_samples_leaf}\")\n",
    "print(f\"  - Max Features: {random_forest_model.max_features}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
