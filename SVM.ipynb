{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f310eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hankerz\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc03d487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (38903, 2)\n",
      "\n",
      "First few rows of training set:\n",
      "                                            response  label\n",
      "0  I'm happy to help! Cutting a flawless diamond ...      1\n",
      "1  I'm sorry, but I cannot assist with questions ...      1\n",
      "2  [ASS] Unfortunately, the character Lara Croft ...      0\n",
      "3  I apologize, but I do not feel comfortable des...      1\n",
      "4  Here are some general tips for overcoming the ...      0\n",
      "\n",
      "Training set class distribution:\n",
      "label\n",
      "1    19478\n",
      "0    19425\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test set shape: (4323, 2)\n",
      "\n",
      "First few rows of test set:\n",
      "                                            response  label\n",
      "0  I'm sorry, I can't provide you with any contac...      1\n",
      "1  That's a detailed and thoughtful guide, AI. Gi...      0\n",
      "2  Certainly, I'd be happy to help you navigate t...      0\n",
      "3  Hello! I'm here to assist you with your questi...      1\n",
      "4  I cannot simulate or provide actual data from ...      1\n",
      "\n",
      "Test set class distribution:\n",
      "label\n",
      "0    2188\n",
      "1    2135\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the training and testing datasets\n",
    "train_df, test_df = pipeline.load_data()\n",
    "\n",
    "# Display basic information about the datasets\n",
    "print(\"Training set shape:\", train_df.shape)\n",
    "print(\"\\nFirst few rows of training set:\")\n",
    "print(train_df.head())\n",
    "print(\"\\nTraining set class distribution:\")\n",
    "print(train_df['label'].value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nTest set shape:\", test_df.shape)\n",
    "print(\"\\nFirst few rows of test set:\")\n",
    "print(test_df.head())\n",
    "print(\"\\nTest set class distribution:\")\n",
    "print(test_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e1f91d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing training data...\n",
      "Preprocessing test data...\n",
      "Preprocessing complete!\n",
      "\n",
      "Sample preprocessed responses:\n",
      "\n",
      "Original: I'm happy to help! Cutting a flawless diamond can be a challenging task, and it requires a great dea\n",
      "Processed: i 'm happy to help cutting a flawless diamond can be a challenging task and it requires a great deal\n",
      "\n",
      "Original: I'm sorry, but I cannot assist with questions that seek to amplify or validate harmful myths or disc\n",
      "Processed: i 'm sorry but i can not assist with question that seek to amplify or validate harmful myth or discr\n",
      "\n",
      "Original: [ASS] Unfortunately, the character Lara Croft from the video game Tomb Raider does not have a passpo\n",
      "Processed: as unfortunately the character lara croft from the video game tomb raider doe not have a passport in\n"
     ]
    }
   ],
   "source": [
    "# PREPROCESSING PIPELINE\n",
    "print(\"Preprocessing training data...\")\n",
    "train_df['processed_response'] = train_df['response'].apply(lambda x: pipeline.preprocess_text(x)[0])\n",
    "train_df['tokens'] = train_df['response'].apply(lambda x: pipeline.preprocess_text(x)[1])\n",
    "\n",
    "print(\"Preprocessing test data...\")\n",
    "test_df['processed_response'] = test_df['response'].apply(lambda x: pipeline.preprocess_text(x)[0])\n",
    "test_df['tokens'] = test_df['response'].apply(lambda x: pipeline.preprocess_text(x)[1])\n",
    "\n",
    "print(\"Preprocessing complete!\")\n",
    "print(\"\\nSample preprocessed responses:\")\n",
    "for i in range(3):\n",
    "    print(f\"\\nOriginal: {train_df['response'].iloc[i][:100]}\")\n",
    "    print(f\"Processed: {train_df['processed_response'].iloc[i][:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39c1c60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting length features...\n",
      "Extracting refusal keyword features...\n",
      "Extracting sentiment features...\n",
      "Extracting structure features...\n",
      "Extracting apologetic tone features...\n",
      "\n",
      "Feature extraction complete!\n"
     ]
    }
   ],
   "source": [
    "# FEATURE EXTRACTION \n",
    "train_engineered_features, test_engineered_features = pipeline.extract_all_features(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d24997c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating TF-IDF features...\n",
      "TF-IDF shape - Train: (38903, 3000), Test: (4323, 3000)\n",
      "Vectorization complete!\n"
     ]
    }
   ],
   "source": [
    "# VECTORIZATION - TF-IDF\n",
    "train_tfidf_df, test_tfidf_df = pipeline.vectorize_tfidf(train_df, test_df)\n",
    "\n",
    "print(\"Vectorization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2715452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained embedding model...\n",
      "Using 'all-MiniLM-L6-v2' - a lightweight, fast sentence transformer model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 809.15it/s, Materializing param=pooler.dense.weight]                             \n",
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1216/1216 [10:28<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training embeddings shape: (38903, 384)\n",
      "\n",
      "Generating embeddings for test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 136/136 [01:10<00:00,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test embeddings shape: (4323, 384)\n",
      "\n",
      "Embedding features created:\n",
      "  - Train shape: (38903, 384)\n",
      "  - Test shape: (4323, 384)\n",
      "\n",
      "Embeddings generated successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# PRETRAINED EMBEDDINGS - Use Sentence-BERT (Universal Sentence Encoder alternative)\n",
    "\n",
    "print(\"Loading pretrained embedding model...\")\n",
    "print(\"Using 'all-MiniLM-L6-v2' - a lightweight, fast sentence transformer model\")\n",
    "\n",
    "# Load pretrained sentence transformer model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "print(\"Generating embeddings for training data...\")\n",
    "# Generate embeddings for original responses (not processed text)\n",
    "train_embeddings = embedding_model.encode(train_df['response'].tolist(), show_progress_bar=True)\n",
    "print(f\"Training embeddings shape: {train_embeddings.shape}\")\n",
    "\n",
    "print(\"\\nGenerating embeddings for test data...\")\n",
    "test_embeddings = embedding_model.encode(test_df['response'].tolist(), show_progress_bar=True)\n",
    "print(f\"Test embeddings shape: {test_embeddings.shape}\")\n",
    "\n",
    "# Create dataframes for embeddings\n",
    "train_embeddings_df = pd.DataFrame(train_embeddings, columns=[f'embedding_{i}' for i in range(train_embeddings.shape[1])])\n",
    "test_embeddings_df = pd.DataFrame(test_embeddings, columns=[f'embedding_{i}' for i in range(test_embeddings.shape[1])])\n",
    "\n",
    "print(f\"\\nEmbedding features created:\")\n",
    "print(f\"  - Train shape: {train_embeddings_df.shape}\")\n",
    "print(f\"  - Test shape: {test_embeddings_df.shape}\")\n",
    "print(\"\\nEmbeddings generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d056dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered features shape:\n",
      "Train: (38903, 23)\n",
      "Test: (4323, 23)\n",
      "\n",
      "============================================================\n",
      "FINAL FEATURE SET FOR LINEAR SVM\n",
      "============================================================\n",
      "Total features: 3407\n",
      "Training samples: 38903\n",
      "Test samples: 4323\n",
      "\n",
      "Feature breakdown:\n",
      "  - Engineered features (scaled): 23\n",
      "  - TF-IDF features: 3000\n",
      "  - Pretrained embeddings: 384\n",
      "\n",
      "Scaling features for SVM...\n",
      "Feature scaling complete!\n",
      "Scaled training shape: (38903, 3407)\n",
      "Scaled test shape: (4323, 3407)\n"
     ]
    }
   ],
   "source": [
    "# FEATURE COMBINATION - Combine all features (engineered + TF-IDF + embeddings)\n",
    "print(\"Engineered features shape:\")\n",
    "print(f\"Train: {train_engineered_features.shape}\")\n",
    "print(f\"Test: {test_engineered_features.shape}\")\n",
    "\n",
    "# Scale engineered features to [0, 1] range for better SVM performance\n",
    "scaler_engineered = MinMaxScaler()\n",
    "train_engineered_scaled = scaler_engineered.fit_transform(train_engineered_features)\n",
    "test_engineered_scaled = scaler_engineered.transform(test_engineered_features)\n",
    "\n",
    "train_engineered_scaled_df = pd.DataFrame(train_engineered_scaled, columns=train_engineered_features.columns)\n",
    "test_engineered_scaled_df = pd.DataFrame(test_engineered_scaled, columns=test_engineered_features.columns)\n",
    "\n",
    "# Combine all features: engineered + TF-IDF + embeddings\n",
    "train_X = pd.concat([\n",
    "    train_engineered_scaled_df,\n",
    "    train_tfidf_df,\n",
    "    train_embeddings_df\n",
    "], axis=1)\n",
    "\n",
    "test_X = pd.concat([\n",
    "    test_engineered_scaled_df,\n",
    "    test_tfidf_df,\n",
    "    test_embeddings_df\n",
    "], axis=1)\n",
    "\n",
    "train_y = train_df['label']\n",
    "test_y = test_df['label']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL FEATURE SET FOR LINEAR SVM\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total features: {train_X.shape[1]}\")\n",
    "print(f\"Training samples: {train_X.shape[0]}\")\n",
    "print(f\"Test samples: {test_X.shape[0]}\")\n",
    "print(f\"\\nFeature breakdown:\")\n",
    "print(f\"  - Engineered features (scaled): {train_engineered_scaled_df.shape[1]}\")\n",
    "print(f\"  - TF-IDF features: {train_tfidf_df.shape[1]}\")\n",
    "print(f\"  - Pretrained embeddings: {train_embeddings_df.shape[1]}\")\n",
    "\n",
    "# Scale all features for SVM (standardization is important for SVM)\n",
    "print(\"\\nScaling features for SVM...\")\n",
    "scaler_svm = StandardScaler()\n",
    "train_X_scaled = scaler_svm.fit_transform(train_X)\n",
    "test_X_scaled = scaler_svm.transform(test_X)\n",
    "\n",
    "print(\"Feature scaling complete!\")\n",
    "print(f\"Scaled training shape: {train_X_scaled.shape}\")\n",
    "print(f\"Scaled test shape: {test_X_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02bbbac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear SVM model...\n",
      "Using LinearSVC with squared hinge loss and L2 penalty\n",
      "Linear SVM model trained successfully!\n",
      "Model classes: [0 1]\n",
      "Number of features used: 3407\n"
     ]
    }
   ],
   "source": [
    "# MODEL TRAINING - Linear SVM\n",
    "\n",
    "print(\"Training Linear SVM model...\")\n",
    "print(\"Using LinearSVC with squared hinge loss and L2 penalty\")\n",
    "\n",
    "# LinearSVC is faster than SVC with linear kernel for large datasets\n",
    "# dual=False is recommended when n_samples > n_features (which it is here)\n",
    "svm_model = LinearSVC(\n",
    "    C=1.0,                  # Regularization parameter\n",
    "    loss='squared_hinge',   # Loss function\n",
    "    penalty='l2',           # Penalty type\n",
    "    dual=False,             # Optimization formulation\n",
    "    max_iter=2000,          # Maximum iterations\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "svm_model.fit(train_X_scaled, train_y)\n",
    "\n",
    "print(\"Linear SVM model trained successfully!\")\n",
    "print(f\"Model classes: {svm_model.classes_}\")\n",
    "print(f\"Number of features used: {svm_model.n_features_in_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "866d8c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TOP FEATURE IMPORTANCE (SVM Coefficients)\n",
      "============================================================\n",
      "\n",
      "Top 20 Most Important Features (by absolute coefficient):\n",
      "                       feature  coefficient  abs_coefficient\n",
      "46                    tfidf_23     0.782415         0.782415\n",
      "47                    tfidf_24    -0.753905         0.753905\n",
      "1                   word_count     0.749753         0.749753\n",
      "3246             embedding_223    -0.693919         0.693919\n",
      "0              response_length    -0.669910         0.669910\n",
      "2391                tfidf_2368     0.665386         0.665386\n",
      "3                char_per_word     0.555888         0.555888\n",
      "2              avg_word_length    -0.548344         0.548344\n",
      "1707                tfidf_1684     0.518532         0.518532\n",
      "3150             embedding_127    -0.505680         0.505680\n",
      "1704                tfidf_1681     0.490301         0.490301\n",
      "4     refusal_keyword_at_start     0.459402         0.459402\n",
      "2776                tfidf_2753    -0.447794         0.447794\n",
      "81                    tfidf_58    -0.429963         0.429963\n",
      "80                    tfidf_57     0.422759         0.422759\n",
      "2132                tfidf_2109    -0.411134         0.411134\n",
      "20           formal_word_count     0.410847         0.410847\n",
      "2081                tfidf_2058    -0.396696         0.396696\n",
      "2080                tfidf_2057     0.393704         0.393704\n",
      "2131                tfidf_2108     0.392722         0.392722\n",
      "\n",
      "\n",
      "Top 10 Engineered Features Contributing to REFUSAL prediction:\n",
      "                     feature  coefficient  abs_coefficient\n",
      "4   refusal_keyword_at_start     0.459402         0.459402\n",
      "20         formal_word_count     0.410847         0.410847\n",
      "6    has_any_refusal_keyword     0.172725         0.172725\n",
      "5    refusal_keyword_overall     0.084207         0.084207\n",
      "14         punctuation_count     0.049151         0.049151\n",
      "17           uppercase_ratio     0.020742         0.020742\n",
      "8     sentiment_subjectivity     0.015405         0.015405\n",
      "19        apology_word_count     0.014226         0.014226\n",
      "9      is_negative_sentiment     0.011500         0.011500\n",
      "16         exclamation_count     0.008519         0.008519\n",
      "\n",
      "\n",
      "Top 10 TF-IDF Features Contributing to REFUSAL prediction:\n",
      "         feature  coefficient\n",
      "46      tfidf_23     0.782415\n",
      "2391  tfidf_2368     0.665386\n",
      "1707  tfidf_1684     0.518532\n",
      "1704  tfidf_1681     0.490301\n",
      "80      tfidf_57     0.422759\n",
      "2080  tfidf_2057     0.393704\n",
      "2131  tfidf_2108     0.392722\n",
      "2777  tfidf_2754     0.391282\n",
      "1706  tfidf_1683     0.377579\n",
      "1348  tfidf_1325     0.373776\n",
      "\n",
      "\n",
      "Model Summary:\n",
      "Total Features Used: 3407\n",
      "  - Engineered Features: 23\n",
      "  - TF-IDF Features: 3000\n",
      "  - Embedding Features: 384\n",
      "\n",
      "Model Hyperparameters:\n",
      "  - Regularization (C): 1.0\n",
      "  - Loss Function: squared_hinge\n",
      "  - Penalty: l2\n"
     ]
    }
   ],
   "source": [
    "# FEATURE IMPORTANCE ANALYSIS - SVM Coefficients\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TOP FEATURE IMPORTANCE (SVM Coefficients)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get feature coefficients from SVM\n",
    "feature_names = list(train_engineered_scaled_df.columns) + list(train_tfidf_df.columns) + list(train_embeddings_df.columns)\n",
    "coefficients = svm_model.coef_[0]\n",
    "\n",
    "# Create feature importance dataframe\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'coefficient': coefficients,\n",
    "    'abs_coefficient': np.abs(coefficients)\n",
    "}).sort_values('abs_coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 Most Important Features (by absolute coefficient):\")\n",
    "print(feature_importance_df.head(20).to_string())\n",
    "\n",
    "print(\"\\n\\nTop 10 Engineered Features Contributing to REFUSAL prediction:\")\n",
    "engineered_features_only = feature_importance_df[feature_importance_df['feature'].str.contains('^(response_|refusal_|sentiment_|is_|sentence_|punctuation_|question_|exclamation_|uppercase_|has_|apology_|formal_)', regex=True)]\n",
    "top_engineered_refusal = engineered_features_only[engineered_features_only['coefficient'] > 0].head(10)\n",
    "if len(top_engineered_refusal) > 0:\n",
    "    print(top_engineered_refusal.to_string())\n",
    "else:\n",
    "    print(\"No positive engineered features in top contributors\")\n",
    "\n",
    "print(\"\\n\\nTop 10 TF-IDF Features Contributing to REFUSAL prediction:\")\n",
    "tfidf_features_only = feature_importance_df[feature_importance_df['feature'].str.startswith('tfidf_')]\n",
    "top_tfidf_refusal = tfidf_features_only[tfidf_features_only['coefficient'] > 0].head(10)\n",
    "if len(top_tfidf_refusal) > 0:\n",
    "    print(top_tfidf_refusal[['feature', 'coefficient']].to_string())\n",
    "\n",
    "print(\"\\n\\nModel Summary:\")\n",
    "print(f\"Total Features Used: {len(feature_names)}\")\n",
    "print(f\"  - Engineered Features: {len(train_engineered_scaled_df.columns)}\")\n",
    "print(f\"  - TF-IDF Features: {len(train_tfidf_df.columns)}\")\n",
    "print(f\"  - Embedding Features: {len(train_embeddings_df.columns)}\")\n",
    "print(f\"\\nModel Hyperparameters:\")\n",
    "print(f\"  - Regularization (C): {svm_model.C}\")\n",
    "print(f\"  - Loss Function: squared_hinge\")\n",
    "print(f\"  - Penalty: l2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85d2f023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING SET EVALUATION\n",
      "============================================================\n",
      "\n",
      "Accuracy:  0.9710\n",
      "Precision: 0.9769\n",
      "Recall:    0.9648\n",
      "F1-Score:  0.9708\n",
      "\n",
      "Confusion Matrix (Training):\n",
      "[[18981   444]\n",
      " [  685 18793]]\n",
      "\n",
      "True Negatives: 18981\n",
      "False Positives: 444\n",
      "False Negatives: 685\n",
      "True Positives: 18793\n"
     ]
    }
   ],
   "source": [
    "# MODEL EVALUATION - Training Set\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SET EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "y_train_pred = svm_model.predict(train_X_scaled)\n",
    "y_train_decision = svm_model.decision_function(train_X_scaled)\n",
    "\n",
    "train_accuracy = accuracy_score(train_y, y_train_pred)\n",
    "train_precision = precision_score(train_y, y_train_pred)\n",
    "train_recall = recall_score(train_y, y_train_pred)\n",
    "train_f1 = f1_score(train_y, y_train_pred)\n",
    "\n",
    "print(f\"\\nAccuracy:  {train_accuracy:.4f}\")\n",
    "print(f\"Precision: {train_precision:.4f}\")\n",
    "print(f\"Recall:    {train_recall:.4f}\")\n",
    "print(f\"F1-Score:  {train_f1:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix (Training):\")\n",
    "cm_train = confusion_matrix(train_y, y_train_pred)\n",
    "print(cm_train)\n",
    "print(f\"\\nTrue Negatives: {cm_train[0,0]}\")\n",
    "print(f\"False Positives: {cm_train[0,1]}\")\n",
    "print(f\"False Negatives: {cm_train[1,0]}\")\n",
    "print(f\"True Positives: {cm_train[1,1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4fc4515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEST SET EVALUATION\n",
      "============================================================\n",
      "\n",
      "Accuracy:  0.9227\n",
      "Precision: 0.9202\n",
      "Recall:    0.9237\n",
      "F1-Score:  0.9219\n",
      "\n",
      "Confusion Matrix (Test):\n",
      "[[2017  171]\n",
      " [ 163 1972]]\n",
      "\n",
      "True Negatives: 2017\n",
      "False Positives: 171\n",
      "False Negatives: 163\n",
      "True Positives: 1972\n",
      "\n",
      "============================================================\n",
      "Detailed Classification Report (Test):\n",
      "============================================================\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Not Refusal (0)       0.93      0.92      0.92      2188\n",
      "    Refusal (1)       0.92      0.92      0.92      2135\n",
      "\n",
      "       accuracy                           0.92      4323\n",
      "      macro avg       0.92      0.92      0.92      4323\n",
      "   weighted avg       0.92      0.92      0.92      4323\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MODEL EVALUATION - Test Set\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST SET EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "y_test_pred = svm_model.predict(test_X_scaled)\n",
    "y_test_decision = svm_model.decision_function(test_X_scaled)\n",
    "\n",
    "test_accuracy = accuracy_score(test_y, y_test_pred)\n",
    "test_precision = precision_score(test_y, y_test_pred)\n",
    "test_recall = recall_score(test_y, y_test_pred)\n",
    "test_f1 = f1_score(test_y, y_test_pred)\n",
    "\n",
    "print(f\"\\nAccuracy:  {test_accuracy:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall:    {test_recall:.4f}\")\n",
    "print(f\"F1-Score:  {test_f1:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix (Test):\")\n",
    "cm_test = confusion_matrix(test_y, y_test_pred)\n",
    "print(cm_test)\n",
    "print(f\"\\nTrue Negatives: {cm_test[0,0]}\")\n",
    "print(f\"False Positives: {cm_test[0,1]}\")\n",
    "print(f\"False Negatives: {cm_test[1,0]}\")\n",
    "print(f\"True Positives: {cm_test[1,1]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Detailed Classification Report (Test):\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(test_y, y_test_pred, target_names=['Not Refusal (0)', 'Refusal (1)']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
