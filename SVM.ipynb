{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f310eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc03d487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (38903, 2)\n",
      "\n",
      "First few rows of training set:\n",
      "                                            response  label\n",
      "0  I'm happy to help! Cutting a flawless diamond ...      1\n",
      "1  I'm sorry, but I cannot assist with questions ...      1\n",
      "2  [ASS] Unfortunately, the character Lara Croft ...      0\n",
      "3  I apologize, but I do not feel comfortable des...      1\n",
      "4  Here are some general tips for overcoming the ...      0\n",
      "\n",
      "Training set class distribution:\n",
      "label\n",
      "1    19478\n",
      "0    19425\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test set shape: (4323, 2)\n",
      "\n",
      "First few rows of test set:\n",
      "                                            response  label\n",
      "0  I'm sorry, I can't provide you with any contac...      1\n",
      "1  That's a detailed and thoughtful guide, AI. Gi...      0\n",
      "2  Certainly, I'd be happy to help you navigate t...      0\n",
      "3  Hello! I'm here to assist you with your questi...      1\n",
      "4  I cannot simulate or provide actual data from ...      1\n",
      "\n",
      "Test set class distribution:\n",
      "label\n",
      "0    2188\n",
      "1    2135\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the training and testing datasets\n",
    "train_df, test_df = pipeline.load_data()\n",
    "\n",
    "# Display basic information about the datasets\n",
    "print(\"Training set shape:\", train_df.shape)\n",
    "print(\"\\nFirst few rows of training set:\")\n",
    "print(train_df.head())\n",
    "print(\"\\nTraining set class distribution:\")\n",
    "print(train_df['label'].value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nTest set shape:\", test_df.shape)\n",
    "print(\"\\nFirst few rows of test set:\")\n",
    "print(test_df.head())\n",
    "print(\"\\nTest set class distribution:\")\n",
    "print(test_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e1f91d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing training data...\n",
      "Preprocessing test data...\n",
      "Preprocessing complete!\n",
      "\n",
      "Sample preprocessed responses:\n",
      "\n",
      "Original: I'm happy to help! Cutting a flawless diamond can be a challenging task, and it requires a great dea\n",
      "Processed: i am happy to help cutting a flawless diamond can be a challenging task and it requires a great deal\n",
      "\n",
      "Original: I'm sorry, but I cannot assist with questions that seek to amplify or validate harmful myths or disc\n",
      "Processed: i am sorry but i can not assist with question that seek to amplify or validate harmful myth or discr\n",
      "\n",
      "Original: [ASS] Unfortunately, the character Lara Croft from the video game Tomb Raider does not have a passpo\n",
      "Processed: as unfortunately the character lara croft from the video game tomb raider doe not have a passport in\n"
     ]
    }
   ],
   "source": [
    "# PREPROCESSING PIPELINE\n",
    "print(\"Preprocessing training data...\")\n",
    "train_df['processed_response'] = train_df['response'].apply(lambda x: pipeline.preprocess_text(x)[0])\n",
    "train_df['tokens'] = train_df['response'].apply(lambda x: pipeline.preprocess_text(x)[1])\n",
    "\n",
    "print(\"Preprocessing test data...\")\n",
    "test_df['processed_response'] = test_df['response'].apply(lambda x: pipeline.preprocess_text(x)[0])\n",
    "test_df['tokens'] = test_df['response'].apply(lambda x: pipeline.preprocess_text(x)[1])\n",
    "\n",
    "print(\"Preprocessing complete!\")\n",
    "print(\"\\nSample preprocessed responses:\")\n",
    "for i in range(3):\n",
    "    print(f\"\\nOriginal: {train_df['response'].iloc[i][:100]}\")\n",
    "    print(f\"Processed: {train_df['processed_response'].iloc[i][:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39c1c60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting length features...\n",
      "Extracting refusal keyword features...\n",
      "Extracting sentiment features...\n",
      "Extracting structure features...\n",
      "Extracting apologetic tone features...\n",
      "Extracting first-person pronoun features...\n",
      "Extracting hedging language features...\n",
      "Extracting opening pattern features...\n",
      "Extracting negation features...\n",
      "\n",
      "Feature extraction complete!\n"
     ]
    }
   ],
   "source": [
    "# FEATURE EXTRACTION \n",
    "train_engineered_features, test_engineered_features = pipeline.extract_all_features(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d24997c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating TF-IDF features...\n",
      "TF-IDF shape - Train: (38903, 3000), Test: (4323, 3000)\n",
      "Vectorization complete!\n"
     ]
    }
   ],
   "source": [
    "# VECTORIZATION - TF-IDF\n",
    "train_tfidf_df, test_tfidf_df = pipeline.vectorize_tfidf(train_df, test_df)\n",
    "\n",
    "print(\"Vectorization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2715452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained embedding model...\n",
      "Using 'all-MiniLM-L6-v2' - a lightweight, fast sentence transformer model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 787.86it/s, Materializing param=pooler.dense.weight]                             \n",
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1216/1216 [13:46<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training embeddings shape: (38903, 384)\n",
      "\n",
      "Generating embeddings for test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 136/136 [01:27<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test embeddings shape: (4323, 384)\n",
      "\n",
      "Embedding features created:\n",
      "  - Train shape: (38903, 384)\n",
      "  - Test shape: (4323, 384)\n",
      "\n",
      "Embeddings generated successfully!\n"
     ]
    }
   ],
   "source": [
    "# PRETRAINED EMBEDDINGS - Use Sentence-BERT (Universal Sentence Encoder alternative)\n",
    "\n",
    "print(\"Loading pretrained embedding model...\")\n",
    "print(\"Using 'all-MiniLM-L6-v2' - a lightweight, fast sentence transformer model\")\n",
    "\n",
    "# Load pretrained sentence transformer model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "print(\"Generating embeddings for training data...\")\n",
    "# Generate embeddings for original responses (not processed text)\n",
    "train_embeddings = embedding_model.encode(train_df['response'].tolist(), show_progress_bar=True)\n",
    "print(f\"Training embeddings shape: {train_embeddings.shape}\")\n",
    "\n",
    "print(\"\\nGenerating embeddings for test data...\")\n",
    "test_embeddings = embedding_model.encode(test_df['response'].tolist(), show_progress_bar=True)\n",
    "print(f\"Test embeddings shape: {test_embeddings.shape}\")\n",
    "\n",
    "# Create dataframes for embeddings\n",
    "train_embeddings_df = pd.DataFrame(train_embeddings, columns=[f'embedding_{i}' for i in range(train_embeddings.shape[1])])\n",
    "test_embeddings_df = pd.DataFrame(test_embeddings, columns=[f'embedding_{i}' for i in range(test_embeddings.shape[1])])\n",
    "\n",
    "print(f\"\\nEmbedding features created:\")\n",
    "print(f\"  - Train shape: {train_embeddings_df.shape}\")\n",
    "print(f\"  - Test shape: {test_embeddings_df.shape}\")\n",
    "print(\"\\nEmbeddings generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d056dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered features shape:\n",
      "Train: (38903, 30)\n",
      "Test: (4323, 30)\n",
      "\n",
      "============================================================\n",
      "FINAL FEATURE SET FOR LINEAR SVM\n",
      "============================================================\n",
      "Total features: 3414\n",
      "Training samples: 38903\n",
      "Test samples: 4323\n",
      "\n",
      "Feature breakdown:\n",
      "  - Engineered features (scaled): 30\n",
      "  - TF-IDF features: 3000\n",
      "  - Pretrained embeddings: 384\n",
      "\n",
      "Scaling features for SVM...\n",
      "Feature scaling complete!\n",
      "Scaled training shape: (38903, 3414)\n",
      "Scaled test shape: (4323, 3414)\n"
     ]
    }
   ],
   "source": [
    "# FEATURE COMBINATION - Combine all features (engineered + TF-IDF + embeddings)\n",
    "print(\"Engineered features shape:\")\n",
    "print(f\"Train: {train_engineered_features.shape}\")\n",
    "print(f\"Test: {test_engineered_features.shape}\")\n",
    "\n",
    "# Scale engineered features to [0, 1] range for better SVM performance\n",
    "scaler_engineered = MinMaxScaler()\n",
    "train_engineered_scaled = scaler_engineered.fit_transform(train_engineered_features)\n",
    "test_engineered_scaled = scaler_engineered.transform(test_engineered_features)\n",
    "\n",
    "train_engineered_scaled_df = pd.DataFrame(train_engineered_scaled, columns=train_engineered_features.columns)\n",
    "test_engineered_scaled_df = pd.DataFrame(test_engineered_scaled, columns=test_engineered_features.columns)\n",
    "\n",
    "# Combine all features: engineered + TF-IDF + embeddings\n",
    "train_X = pd.concat([\n",
    "    train_engineered_scaled_df,\n",
    "    train_tfidf_df,\n",
    "    train_embeddings_df\n",
    "], axis=1)\n",
    "\n",
    "test_X = pd.concat([\n",
    "    test_engineered_scaled_df,\n",
    "    test_tfidf_df,\n",
    "    test_embeddings_df\n",
    "], axis=1)\n",
    "\n",
    "train_y = train_df['label']\n",
    "test_y = test_df['label']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL FEATURE SET FOR LINEAR SVM\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total features: {train_X.shape[1]}\")\n",
    "print(f\"Training samples: {train_X.shape[0]}\")\n",
    "print(f\"Test samples: {test_X.shape[0]}\")\n",
    "print(f\"\\nFeature breakdown:\")\n",
    "print(f\"  - Engineered features (scaled): {train_engineered_scaled_df.shape[1]}\")\n",
    "print(f\"  - TF-IDF features: {train_tfidf_df.shape[1]}\")\n",
    "print(f\"  - Pretrained embeddings: {train_embeddings_df.shape[1]}\")\n",
    "\n",
    "# Scale all features for SVM (standardization is important for SVM)\n",
    "print(\"\\nScaling features for SVM...\")\n",
    "scaler_svm = StandardScaler()\n",
    "train_X_scaled = scaler_svm.fit_transform(train_X)\n",
    "test_X_scaled = scaler_svm.transform(test_X)\n",
    "\n",
    "print(\"Feature scaling complete!\")\n",
    "print(f\"Scaled training shape: {train_X_scaled.shape}\")\n",
    "print(f\"Scaled test shape: {test_X_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02bbbac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "HYPERPARAMETER TUNING - GridSearchCV\n",
      "============================================================\n",
      "\n",
      "Parameter Grid:\n",
      "  - C: [0.01, 0.1, 1.0, 10.0]\n",
      "  - loss: ['hinge', 'squared_hinge']\n",
      "  - penalty: ['l2']\n",
      "  - max_iter: [2000]\n",
      "\n",
      "Starting GridSearchCV with 3-fold cross-validation...\n",
      "Scoring metric: F1-Score\n",
      "Note: Running sequentially (n_jobs=1) to avoid memory issues\n",
      "------------------------------------------------------------\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV] END ......C=0.01, loss=hinge, max_iter=2000, penalty=l2; total time=   1.1s\n",
      "[CV] END ......C=0.01, loss=hinge, max_iter=2000, penalty=l2; total time=   0.9s\n",
      "[CV] END ......C=0.01, loss=hinge, max_iter=2000, penalty=l2; total time=   0.8s\n",
      "[CV] END C=0.01, loss=squared_hinge, max_iter=2000, penalty=l2; total time=  11.3s\n",
      "[CV] END C=0.01, loss=squared_hinge, max_iter=2000, penalty=l2; total time=  14.7s\n",
      "[CV] END C=0.01, loss=squared_hinge, max_iter=2000, penalty=l2; total time=  10.8s\n",
      "[CV] END .......C=0.1, loss=hinge, max_iter=2000, penalty=l2; total time=   0.8s\n",
      "[CV] END .......C=0.1, loss=hinge, max_iter=2000, penalty=l2; total time=   0.8s\n",
      "[CV] END .......C=0.1, loss=hinge, max_iter=2000, penalty=l2; total time=   0.8s\n",
      "[CV] END C=0.1, loss=squared_hinge, max_iter=2000, penalty=l2; total time= 1.2min\n",
      "[CV] END C=0.1, loss=squared_hinge, max_iter=2000, penalty=l2; total time= 1.5min\n",
      "[CV] END C=0.1, loss=squared_hinge, max_iter=2000, penalty=l2; total time=  59.0s\n",
      "[CV] END .......C=1.0, loss=hinge, max_iter=2000, penalty=l2; total time=   0.8s\n",
      "[CV] END .......C=1.0, loss=hinge, max_iter=2000, penalty=l2; total time=   0.7s\n",
      "[CV] END .......C=1.0, loss=hinge, max_iter=2000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=1.0, loss=squared_hinge, max_iter=2000, penalty=l2; total time= 2.1min\n",
      "[CV] END C=1.0, loss=squared_hinge, max_iter=2000, penalty=l2; total time= 2.5min\n",
      "[CV] END C=1.0, loss=squared_hinge, max_iter=2000, penalty=l2; total time= 1.5min\n",
      "[CV] END ......C=10.0, loss=hinge, max_iter=2000, penalty=l2; total time=   0.8s\n",
      "[CV] END ......C=10.0, loss=hinge, max_iter=2000, penalty=l2; total time=   0.7s\n",
      "[CV] END ......C=10.0, loss=hinge, max_iter=2000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=10.0, loss=squared_hinge, max_iter=2000, penalty=l2; total time= 1.7min\n",
      "[CV] END C=10.0, loss=squared_hinge, max_iter=2000, penalty=l2; total time= 2.4min\n",
      "[CV] END C=10.0, loss=squared_hinge, max_iter=2000, penalty=l2; total time= 1.9min\n",
      "\n",
      "============================================================\n",
      "GRID SEARCH RESULTS - ALL PARAMETER COMBINATIONS\n",
      "============================================================\n",
      "\n",
      "Rank  C         Loss            Mean CV F1    Std CV F1   Fit Time (s)\n",
      "----------------------------------------------------------------------\n",
      "1     0.01      squared_hinge   0.9084        0.0016      12.29       \n",
      "2     0.1       squared_hinge   0.8980        0.0022      74.48       \n",
      "3     1.0       squared_hinge   0.8957        0.0023      122.85      \n",
      "4     10.0      squared_hinge   0.8955        0.0020      119.63      \n",
      "5     0.1       hinge           nan           nan         0.88        \n",
      "5     0.01      hinge           nan           nan         1.01        \n",
      "5     1.0       hinge           nan           nan         0.85        \n",
      "5     10.0      hinge           nan           nan         0.84        \n",
      "\n",
      "============================================================\n",
      "BEST PARAMETERS\n",
      "============================================================\n",
      "\n",
      "Best Parameters: {'C': 0.01, 'loss': 'squared_hinge', 'max_iter': 2000, 'penalty': 'l2'}\n",
      "Best Cross-Validation F1-Score: 0.9084\n",
      "\n",
      "============================================================\n",
      "BEST MODEL DETAILS\n",
      "============================================================\n",
      "Model: LinearSVC\n",
      "  - C (Regularization): 0.01\n",
      "  - Loss Function: squared_hinge\n",
      "  - Penalty: l2\n",
      "  - Max Iterations: 2000\n",
      "Model classes: [0 1]\n",
      "Number of features used: 3414\n"
     ]
    }
   ],
   "source": [
    "# MODEL TRAINING - Linear SVM with GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"HYPERPARAMETER TUNING - GridSearchCV\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1.0, 10.0],\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'penalty': ['l2'],\n",
    "    'max_iter': [2000]\n",
    "}\n",
    "\n",
    "print(\"\\nParameter Grid:\")\n",
    "for param, values in param_grid.items():\n",
    "    print(f\"  - {param}: {values}\")\n",
    "\n",
    "# Create base model\n",
    "base_svm = LinearSVC(dual=False, random_state=42, verbose=0)\n",
    "\n",
    "# Create GridSearchCV with memory-efficient settings\n",
    "# n_jobs=1 to avoid memory issues with parallel processing\n",
    "# return_train_score=False to reduce memory usage\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=base_svm,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,                      # Reduced from 5 to 3 folds to save memory\n",
    "    scoring='f1',\n",
    "    n_jobs=1,                  # Sequential execution to avoid memory duplication\n",
    "    verbose=2,\n",
    "    return_train_score=False   # Don't compute training scores to save memory\n",
    ")\n",
    "\n",
    "print(\"\\nStarting GridSearchCV with 3-fold cross-validation...\")\n",
    "print(\"Scoring metric: F1-Score\")\n",
    "print(\"Note: Running sequentially (n_jobs=1) to avoid memory issues\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "grid_search.fit(train_X_scaled, train_y)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GRID SEARCH RESULTS - ALL PARAMETER COMBINATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get results dataframe\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Sort by rank\n",
    "results_df = results_df.sort_values('rank_test_score')\n",
    "\n",
    "# Print results for each parameter combination\n",
    "print(f\"\\n{'Rank':<6}{'C':<10}{'Loss':<16}{'Mean CV F1':<14}{'Std CV F1':<12}{'Fit Time (s)':<12}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for idx, row in results_df.iterrows():\n",
    "    rank = row['rank_test_score']\n",
    "    C = row['param_C']\n",
    "    loss = row['param_loss']\n",
    "    mean_test = row['mean_test_score']\n",
    "    std_test = row['std_test_score']\n",
    "    fit_time = row['mean_fit_time']\n",
    "    print(f\"{rank:<6}{C:<10}{loss:<16}{mean_test:<14.4f}{std_test:<12.4f}{fit_time:<12.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BEST PARAMETERS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBest Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Cross-Validation F1-Score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Use the best model\n",
    "svm_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BEST MODEL DETAILS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: LinearSVC\")\n",
    "print(f\"  - C (Regularization): {svm_model.C}\")\n",
    "print(f\"  - Loss Function: {svm_model.loss}\")\n",
    "print(f\"  - Penalty: {svm_model.penalty}\")\n",
    "print(f\"  - Max Iterations: {svm_model.max_iter}\")\n",
    "print(f\"Model classes: {svm_model.classes_}\")\n",
    "print(f\"Number of features used: {svm_model.n_features_in_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "866d8c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TOP FEATURE IMPORTANCE (SVM Coefficients)\n",
      "============================================================\n",
      "\n",
      "Top 20 Most Important Features (by absolute coefficient):\n",
      "                       feature  coefficient  abs_coefficient\n",
      "5      refusal_keyword_overall     0.359313         0.359313\n",
      "4     refusal_keyword_at_start     0.286611         0.286611\n",
      "20           formal_word_count     0.276275         0.276275\n",
      "2399                tfidf_2369     0.248707         0.248707\n",
      "1360                tfidf_1330     0.239060         0.239060\n",
      "1713                tfidf_1683     0.228159         0.228159\n",
      "1                   word_count     0.198028         0.198028\n",
      "1357                tfidf_1327     0.189485         0.189485\n",
      "24          first_person_ratio     0.186467         0.186467\n",
      "1711                tfidf_1681     0.183401         0.183401\n",
      "2316                tfidf_2286     0.172440         0.172440\n",
      "3304             embedding_274     0.167854         0.167854\n",
      "3175             embedding_145     0.166798         0.166798\n",
      "3099              embedding_69    -0.164026         0.164026\n",
      "2317                tfidf_2287     0.162850         0.162850\n",
      "3368             embedding_338    -0.162288         0.162288\n",
      "148                  tfidf_118    -0.161605         0.161605\n",
      "1359                tfidf_1329     0.161012         0.161012\n",
      "1138                tfidf_1108    -0.160939         0.160939\n",
      "88                    tfidf_58    -0.160926         0.160926\n",
      "\n",
      "\n",
      "Top 10 Engineered Features Contributing to REFUSAL prediction:\n",
      "                     feature  coefficient  abs_coefficient\n",
      "5    refusal_keyword_overall     0.359313         0.359313\n",
      "4   refusal_keyword_at_start     0.286611         0.286611\n",
      "20         formal_word_count     0.276275         0.276275\n",
      "19        apology_word_count     0.017756         0.017756\n",
      "21             is_apologetic     0.015628         0.015628\n",
      "17           uppercase_ratio     0.012391         0.012391\n",
      "9      is_negative_sentiment     0.012365         0.012365\n",
      "16         exclamation_count     0.011559         0.011559\n",
      "11     is_positive_sentiment     0.010874         0.010874\n",
      "7         sentiment_polarity     0.010492         0.010492\n",
      "\n",
      "\n",
      "Top 10 TF-IDF Features Contributing to REFUSAL prediction:\n",
      "         feature  coefficient\n",
      "2399  tfidf_2369     0.248707\n",
      "1360  tfidf_1330     0.239060\n",
      "1713  tfidf_1683     0.228159\n",
      "1357  tfidf_1327     0.189485\n",
      "1711  tfidf_1681     0.183401\n",
      "2316  tfidf_2286     0.172440\n",
      "2317  tfidf_2287     0.162850\n",
      "1359  tfidf_1329     0.161012\n",
      "87      tfidf_57     0.158653\n",
      "1709  tfidf_1679     0.124856\n",
      "\n",
      "\n",
      "Model Summary:\n",
      "Total Features Used: 3414\n",
      "  - Engineered Features: 30\n",
      "  - TF-IDF Features: 3000\n",
      "  - Embedding Features: 384\n",
      "\n",
      "Model Hyperparameters:\n",
      "  - Regularization (C): 0.01\n",
      "  - Loss Function: squared_hinge\n",
      "  - Penalty: l2\n"
     ]
    }
   ],
   "source": [
    "# FEATURE IMPORTANCE ANALYSIS - SVM Coefficients\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TOP FEATURE IMPORTANCE (SVM Coefficients)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get feature coefficients from SVM\n",
    "feature_names = list(train_engineered_scaled_df.columns) + list(train_tfidf_df.columns) + list(train_embeddings_df.columns)\n",
    "coefficients = svm_model.coef_[0]\n",
    "\n",
    "# Create feature importance dataframe\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'coefficient': coefficients,\n",
    "    'abs_coefficient': np.abs(coefficients)\n",
    "}).sort_values('abs_coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 Most Important Features (by absolute coefficient):\")\n",
    "print(feature_importance_df.head(20).to_string())\n",
    "\n",
    "print(\"\\n\\nTop 10 Engineered Features Contributing to REFUSAL prediction:\")\n",
    "engineered_features_only = feature_importance_df[feature_importance_df['feature'].str.contains('^(response_|refusal_|sentiment_|is_|sentence_|punctuation_|question_|exclamation_|uppercase_|has_|apology_|formal_)', regex=True)]\n",
    "top_engineered_refusal = engineered_features_only[engineered_features_only['coefficient'] > 0].head(10)\n",
    "if len(top_engineered_refusal) > 0:\n",
    "    print(top_engineered_refusal.to_string())\n",
    "else:\n",
    "    print(\"No positive engineered features in top contributors\")\n",
    "\n",
    "print(\"\\n\\nTop 10 TF-IDF Features Contributing to REFUSAL prediction:\")\n",
    "tfidf_features_only = feature_importance_df[feature_importance_df['feature'].str.startswith('tfidf_')]\n",
    "top_tfidf_refusal = tfidf_features_only[tfidf_features_only['coefficient'] > 0].head(10)\n",
    "if len(top_tfidf_refusal) > 0:\n",
    "    print(top_tfidf_refusal[['feature', 'coefficient']].to_string())\n",
    "\n",
    "print(\"\\n\\nModel Summary:\")\n",
    "print(f\"Total Features Used: {len(feature_names)}\")\n",
    "print(f\"  - Engineered Features: {len(train_engineered_scaled_df.columns)}\")\n",
    "print(f\"  - TF-IDF Features: {len(train_tfidf_df.columns)}\")\n",
    "print(f\"  - Embedding Features: {len(train_embeddings_df.columns)}\")\n",
    "print(f\"\\nModel Hyperparameters:\")\n",
    "print(f\"  - Regularization (C): {svm_model.C}\")\n",
    "print(f\"  - Loss Function: squared_hinge\")\n",
    "print(f\"  - Penalty: l2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85d2f023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING SET EVALUATION\n",
      "============================================================\n",
      "\n",
      "Accuracy:  0.9695\n",
      "Precision: 0.9777\n",
      "Recall:    0.9609\n",
      "F1-Score:  0.9693\n",
      "\n",
      "Confusion Matrix (Training):\n",
      "[[18999   426]\n",
      " [  761 18717]]\n",
      "\n",
      "True Negatives: 18999\n",
      "False Positives: 426\n",
      "False Negatives: 761\n",
      "True Positives: 18717\n"
     ]
    }
   ],
   "source": [
    "# MODEL EVALUATION - Training Set\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SET EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "y_train_pred = svm_model.predict(train_X_scaled)\n",
    "y_train_decision = svm_model.decision_function(train_X_scaled)\n",
    "\n",
    "train_accuracy = accuracy_score(train_y, y_train_pred)\n",
    "train_precision = precision_score(train_y, y_train_pred)\n",
    "train_recall = recall_score(train_y, y_train_pred)\n",
    "train_f1 = f1_score(train_y, y_train_pred)\n",
    "\n",
    "print(f\"\\nAccuracy:  {train_accuracy:.4f}\")\n",
    "print(f\"Precision: {train_precision:.4f}\")\n",
    "print(f\"Recall:    {train_recall:.4f}\")\n",
    "print(f\"F1-Score:  {train_f1:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix (Training):\")\n",
    "cm_train = confusion_matrix(train_y, y_train_pred)\n",
    "print(cm_train)\n",
    "print(f\"\\nTrue Negatives: {cm_train[0,0]}\")\n",
    "print(f\"False Positives: {cm_train[0,1]}\")\n",
    "print(f\"False Negatives: {cm_train[1,0]}\")\n",
    "print(f\"True Positives: {cm_train[1,1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4fc4515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEST SET EVALUATION\n",
      "============================================================\n",
      "\n",
      "Accuracy:  0.9292\n",
      "Precision: 0.9336\n",
      "Recall:    0.9222\n",
      "F1-Score:  0.9279\n",
      "\n",
      "Confusion Matrix (Test):\n",
      "[[2048  140]\n",
      " [ 166 1969]]\n",
      "\n",
      "True Negatives: 2048\n",
      "False Positives: 140\n",
      "False Negatives: 166\n",
      "True Positives: 1969\n",
      "\n",
      "============================================================\n",
      "Detailed Classification Report (Test):\n",
      "============================================================\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Not Refusal (0)       0.93      0.94      0.93      2188\n",
      "    Refusal (1)       0.93      0.92      0.93      2135\n",
      "\n",
      "       accuracy                           0.93      4323\n",
      "      macro avg       0.93      0.93      0.93      4323\n",
      "   weighted avg       0.93      0.93      0.93      4323\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MODEL EVALUATION - Test Set\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST SET EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "y_test_pred = svm_model.predict(test_X_scaled)\n",
    "y_test_decision = svm_model.decision_function(test_X_scaled)\n",
    "\n",
    "test_accuracy = accuracy_score(test_y, y_test_pred)\n",
    "test_precision = precision_score(test_y, y_test_pred)\n",
    "test_recall = recall_score(test_y, y_test_pred)\n",
    "test_f1 = f1_score(test_y, y_test_pred)\n",
    "\n",
    "print(f\"\\nAccuracy:  {test_accuracy:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall:    {test_recall:.4f}\")\n",
    "print(f\"F1-Score:  {test_f1:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix (Test):\")\n",
    "cm_test = confusion_matrix(test_y, y_test_pred)\n",
    "print(cm_test)\n",
    "print(f\"\\nTrue Negatives: {cm_test[0,0]}\")\n",
    "print(f\"False Positives: {cm_test[0,1]}\")\n",
    "print(f\"False Negatives: {cm_test[1,0]}\")\n",
    "print(f\"True Positives: {cm_test[1,1]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Detailed Classification Report (Test):\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(test_y, y_test_pred, target_names=['Not Refusal (0)', 'Refusal (1)']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
