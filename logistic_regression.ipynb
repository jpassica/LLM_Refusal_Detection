{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746c89f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f075547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (38903, 2)\n",
      "\n",
      "First few rows of training set:\n",
      "                                            response  label\n",
      "0  I'm happy to help! Cutting a flawless diamond ...      1\n",
      "1  I'm sorry, but I cannot assist with questions ...      1\n",
      "2  [ASS] Unfortunately, the character Lara Croft ...      0\n",
      "3  I apologize, but I do not feel comfortable des...      1\n",
      "4  Here are some general tips for overcoming the ...      0\n",
      "\n",
      "Training set class distribution:\n",
      "label\n",
      "1    19478\n",
      "0    19425\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Test set shape: (4323, 2)\n",
      "\n",
      "First few rows of test set:\n",
      "                                            response  label\n",
      "0  I'm sorry, I can't provide you with any contac...      1\n",
      "1  That's a detailed and thoughtful guide, AI. Gi...      0\n",
      "2  Certainly, I'd be happy to help you navigate t...      0\n",
      "3  Hello! I'm here to assist you with your questi...      1\n",
      "4  I cannot simulate or provide actual data from ...      1\n",
      "\n",
      "Test set class distribution:\n",
      "label\n",
      "0    2188\n",
      "1    2135\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the training and testing datasets\n",
    "train_df, test_df = pipeline.load_data()\n",
    "\n",
    "# Display basic information about the datasets\n",
    "print(\"Training set shape:\", train_df.shape)\n",
    "print(\"\\nFirst few rows of training set:\")\n",
    "print(train_df.head())\n",
    "print(\"\\nTraining set class distribution:\")\n",
    "print(train_df['label'].value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nTest set shape:\", test_df.shape)\n",
    "print(\"\\nFirst few rows of test set:\")\n",
    "print(test_df.head())\n",
    "print(\"\\nTest set class distribution:\")\n",
    "print(test_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a12f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing training data...\n",
      "Preprocessing test data...\n",
      "Preprocessing complete!\n",
      "\n",
      "Sample preprocessed responses:\n",
      "\n",
      "Original: I'm happy to help! Cutting a flawless diamond can be a challenging task, and it requires a great dea\n",
      "Processed: i 'm happy to help cutting a flawless diamond can be a challenging task and it requires a great deal\n",
      "\n",
      "Original: I'm sorry, but I cannot assist with questions that seek to amplify or validate harmful myths or disc\n",
      "Processed: i 'm sorry but i can not assist with question that seek to amplify or validate harmful myth or discr\n",
      "\n",
      "Original: [ASS] Unfortunately, the character Lara Croft from the video game Tomb Raider does not have a passpo\n",
      "Processed: as unfortunately the character lara croft from the video game tomb raider doe not have a passport in\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>label</th>\n",
       "      <th>processed_response</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm happy to help! Cutting a flawless diamond ...</td>\n",
       "      <td>1</td>\n",
       "      <td>i 'm happy to help cutting a flawless diamond ...</td>\n",
       "      <td>[i, 'm, happy, to, help, cutting, a, flawless,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm sorry, but I cannot assist with questions ...</td>\n",
       "      <td>1</td>\n",
       "      <td>i 'm sorry but i can not assist with question ...</td>\n",
       "      <td>[i, 'm, sorry, but, i, can, not, assist, with,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ASS] Unfortunately, the character Lara Croft ...</td>\n",
       "      <td>0</td>\n",
       "      <td>as unfortunately the character lara croft from...</td>\n",
       "      <td>[as, unfortunately, the, character, lara, crof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I apologize, but I do not feel comfortable des...</td>\n",
       "      <td>1</td>\n",
       "      <td>i apologize but i do not feel comfortable desc...</td>\n",
       "      <td>[i, apologize, but, i, do, not, feel, comforta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Here are some general tips for overcoming the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>here are some general tip for overcoming the f...</td>\n",
       "      <td>[here, are, some, general, tip, for, overcomin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            response  label  \\\n",
       "0  I'm happy to help! Cutting a flawless diamond ...      1   \n",
       "1  I'm sorry, but I cannot assist with questions ...      1   \n",
       "2  [ASS] Unfortunately, the character Lara Croft ...      0   \n",
       "3  I apologize, but I do not feel comfortable des...      1   \n",
       "4  Here are some general tips for overcoming the ...      0   \n",
       "\n",
       "                                  processed_response  \\\n",
       "0  i 'm happy to help cutting a flawless diamond ...   \n",
       "1  i 'm sorry but i can not assist with question ...   \n",
       "2  as unfortunately the character lara croft from...   \n",
       "3  i apologize but i do not feel comfortable desc...   \n",
       "4  here are some general tip for overcoming the f...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [i, 'm, happy, to, help, cutting, a, flawless,...  \n",
       "1  [i, 'm, sorry, but, i, can, not, assist, with,...  \n",
       "2  [as, unfortunately, the, character, lara, crof...  \n",
       "3  [i, apologize, but, i, do, not, feel, comforta...  \n",
       "4  [here, are, some, general, tip, for, overcomin...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PREPROCESSING PIPELINE\n",
    "print(\"Preprocessing training data...\")\n",
    "train_df['processed_response'] = train_df['response'].apply(lambda x: pipeline.preprocess_text(x)[0])\n",
    "train_df['tokens'] = train_df['response'].apply(lambda x: pipeline.preprocess_text(x)[1])\n",
    "\n",
    "print(\"Preprocessing test data...\")\n",
    "test_df['processed_response'] = test_df['response'].apply(lambda x: pipeline.preprocess_text(x)[0])\n",
    "test_df['tokens'] = test_df['response'].apply(lambda x: pipeline.preprocess_text(x)[1])\n",
    "\n",
    "print(\"Preprocessing complete!\")\n",
    "print(\"\\nSample preprocessed responses:\")\n",
    "for i in range(3):\n",
    "    print(f\"\\nOriginal: {train_df['response'].iloc[i][:100]}\")\n",
    "    print(f\"Processed: {train_df['processed_response'].iloc[i][:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c83dd31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting length features...\n",
      "Extracting refusal keyword features...\n",
      "Extracting sentiment features...\n",
      "Extracting structure features...\n",
      "Extracting apologetic tone features...\n",
      "\n",
      "Feature extraction complete!\n"
     ]
    }
   ],
   "source": [
    "# FEATURE EXTRACTION \n",
    "train_engineered_features, test_engineered_features = pipeline.extract_all_features(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "372721b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating TF-IDF features...\n",
      "TF-IDF shape - Train: (38903, 3000), Test: (4323, 3000)\n",
      "\n",
      "Generating Count Vectorizer features...\n",
      "Count Vectorizer shape - Train: (38903, 2000), Test: (4323, 2000)\n",
      "\n",
      "Vectorization complete!\n"
     ]
    }
   ],
   "source": [
    "# VECTORIZATION - TF-IDF and Count Vectorizer\n",
    "train_tfidf_df, test_tfidf_df = pipeline.vectorize_tfidf(train_df, test_df)\n",
    "train_count_df, test_count_df = pipeline.vectorize_count(train_df, test_df)\n",
    "\n",
    "print(\"\\nVectorization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf185bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered features shape:\n",
      "Train: (38903, 23)\n",
      "Test: (4323, 23)\n",
      "\n",
      "Engineered features:\n",
      "['response_length', 'word_count', 'avg_word_length', 'char_per_word', 'refusal_keyword_at_start', 'refusal_keyword_overall', 'has_any_refusal_keyword', 'sentiment_polarity', 'sentiment_subjectivity', 'is_negative_sentiment', 'is_neutral_sentiment', 'is_positive_sentiment', 'sentence_count', 'avg_sentence_length', 'punctuation_count', 'question_mark_count', 'exclamation_count', 'uppercase_ratio', 'has_multiple_sentences', 'apology_word_count', 'formal_word_count', 'is_apologetic', 'is_formal']\n",
      "\n",
      "==================================================\n",
      "FINAL FEATURE SET\n",
      "==================================================\n",
      "Total features: 5023\n",
      "Training samples: 38903\n",
      "Test samples: 4323\n",
      "\n",
      "Feature breakdown:\n",
      "  - Engineered features: 23\n",
      "  - TF-IDF features: 3000\n",
      "  - Count Vectorizer features: 2000\n"
     ]
    }
   ],
   "source": [
    "# FEATURE COMBINATION - Combine all engineered features\n",
    "print(\"Engineered features shape:\")\n",
    "print(f\"Train: {train_engineered_features.shape}\")\n",
    "print(f\"Test: {test_engineered_features.shape}\")\n",
    "\n",
    "# Display engineered feature names\n",
    "print(\"\\nEngineered features:\")\n",
    "print(train_engineered_features.columns.tolist())\n",
    "\n",
    "# Combine engineered features with vectorized features\n",
    "train_X = pd.concat([\n",
    "    train_engineered_features,\n",
    "    train_tfidf_df,\n",
    "    train_count_df\n",
    "], axis=1)\n",
    "\n",
    "test_X = pd.concat([\n",
    "    test_engineered_features,\n",
    "    test_tfidf_df,\n",
    "    test_count_df\n",
    "], axis=1)\n",
    "\n",
    "train_y = train_df['label']\n",
    "test_y = test_df['label']\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL FEATURE SET\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total features: {train_X.shape[1]}\")\n",
    "print(f\"Training samples: {train_X.shape[0]}\")\n",
    "print(f\"Test samples: {test_X.shape[0]}\")\n",
    "print(f\"\\nFeature breakdown:\")\n",
    "print(f\"  - Engineered features: {train_engineered_features.shape[1]}\")\n",
    "print(f\"  - TF-IDF features: {train_tfidf_df.shape[1]}\")\n",
    "print(f\"  - Count Vectorizer features: {train_count_df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4b1e530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling features...\n",
      "Features scaled successfully!\n",
      "Scaled training shape: (38903, 5023)\n",
      "Scaled test shape: (4323, 5023)\n"
     ]
    }
   ],
   "source": [
    "# FEATURE SCALING - Important for Logistic Regression\n",
    "\n",
    "print(\"Scaling features...\")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit scaler on training data and transform both train and test\n",
    "train_X_scaled = scaler.fit_transform(train_X)\n",
    "test_X_scaled = scaler.transform(test_X)\n",
    "\n",
    "print(\"Features scaled successfully!\")\n",
    "print(f\"Scaled training shape: {train_X_scaled.shape}\")\n",
    "print(f\"Scaled test shape: {test_X_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e23835b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression model...\n",
      "Logistic Regression model trained successfully!\n",
      "Model classes: [0 1]\n",
      "Model intercept: [6.58866232]\n",
      "Number of features used: 5023\n"
     ]
    }
   ],
   "source": [
    "# MODEL TRAINING \n",
    "\n",
    "print(\"Training Logistic Regression model...\")\n",
    "log_reg_model = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1, solver='lbfgs')\n",
    "log_reg_model.fit(train_X_scaled, train_y)\n",
    "\n",
    "print(\"Logistic Regression model trained successfully!\")\n",
    "print(f\"Model classes: {log_reg_model.classes_}\")\n",
    "print(f\"Model intercept: {log_reg_model.intercept_}\")\n",
    "print(f\"Number of features used: {log_reg_model.n_features_in_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0285d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TOP FEATURE IMPORTANCE (Logistic Regression Coefficients)\n",
      "============================================================\n",
      "\n",
      "Top 20 Most Important Features (by absolute coefficient):\n",
      "                       feature  coefficient  abs_coefficient\n",
      "20           formal_word_count     3.663747         3.663747\n",
      "4     refusal_keyword_at_start     3.082610         3.082610\n",
      "3886                 count_863     2.484431         2.484431\n",
      "4553                count_1530     2.356712         2.356712\n",
      "6      has_any_refusal_keyword     2.278657         2.278657\n",
      "4146                count_1123     2.040851         2.040851\n",
      "3804                 count_781     2.009436         2.009436\n",
      "1706                tfidf_1683     1.939828         1.939828\n",
      "80                    tfidf_57     1.742301         1.742301\n",
      "4924                count_1901    -1.735808         1.735808\n",
      "412                  tfidf_389    -1.733673         1.733673\n",
      "4610                count_1587     1.724934         1.724934\n",
      "1702                tfidf_1679     1.715393         1.715393\n",
      "29                     tfidf_6    -1.685535         1.685535\n",
      "1411                tfidf_1388     1.676250         1.676250\n",
      "16           exclamation_count    -1.674132         1.674132\n",
      "1995                tfidf_1972     1.637222         1.637222\n",
      "1219                tfidf_1196    -1.622801         1.622801\n",
      "1386                tfidf_1363    -1.617743         1.617743\n",
      "3888                 count_865     1.607198         1.607198\n",
      "\n",
      "\n",
      "Top 10 Features Contributing to REFUSAL prediction (positive coefficients):\n",
      "                       feature  coefficient  abs_coefficient\n",
      "20           formal_word_count     3.663747         3.663747\n",
      "4     refusal_keyword_at_start     3.082610         3.082610\n",
      "3886                 count_863     2.484431         2.484431\n",
      "4553                count_1530     2.356712         2.356712\n",
      "6      has_any_refusal_keyword     2.278657         2.278657\n",
      "4146                count_1123     2.040851         2.040851\n",
      "3804                 count_781     2.009436         2.009436\n",
      "1706                tfidf_1683     1.939828         1.939828\n",
      "80                    tfidf_57     1.742301         1.742301\n",
      "4610                count_1587     1.724934         1.724934\n",
      "\n",
      "\n",
      "Top 10 Features Contributing to NOT REFUSAL prediction (negative coefficients):\n",
      "                feature  coefficient  abs_coefficient\n",
      "4924         count_1901    -1.735808         1.735808\n",
      "412           tfidf_389    -1.733673         1.733673\n",
      "29              tfidf_6    -1.685535         1.685535\n",
      "16    exclamation_count    -1.674132         1.674132\n",
      "1219         tfidf_1196    -1.622801         1.622801\n",
      "1386         tfidf_1363    -1.617743         1.617743\n",
      "22            is_formal    -1.590397         1.590397\n",
      "1988         tfidf_1965    -1.582085         1.582085\n",
      "3845          count_822    -1.564147         1.564147\n",
      "2592         tfidf_2569    -1.529019         1.529019\n"
     ]
    }
   ],
   "source": [
    "# FEATURE IMPORTANCE ANALYSIS\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TOP FEATURE IMPORTANCE (Logistic Regression Coefficients)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get feature coefficients\n",
    "feature_names = train_X.columns.tolist()\n",
    "coefficients = log_reg_model.coef_[0]\n",
    "\n",
    "# Create feature importance dataframe\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'coefficient': coefficients,\n",
    "    'abs_coefficient': np.abs(coefficients)\n",
    "}).sort_values('abs_coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 Most Important Features (by absolute coefficient):\")\n",
    "print(feature_importance_df.head(20).to_string())\n",
    "\n",
    "print(\"\\n\\nTop 10 Features Contributing to REFUSAL prediction (positive coefficients):\")\n",
    "top_refusal = feature_importance_df[feature_importance_df['coefficient'] > 0].head(10)\n",
    "print(top_refusal.to_string())\n",
    "\n",
    "print(\"\\n\\nTop 10 Features Contributing to NOT REFUSAL prediction (negative coefficients):\")\n",
    "top_not_refusal = feature_importance_df[feature_importance_df['coefficient'] < 0].head(10)\n",
    "print(top_not_refusal.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24e0cd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING SET EVALUATION\n",
      "============================================================\n",
      "\n",
      "Accuracy:  0.9973\n",
      "Precision: 0.9984\n",
      "Recall:    0.9961\n",
      "F1-Score:  0.9973\n",
      "\n",
      "Confusion Matrix (Training):\n",
      "[[19394    31]\n",
      " [   75 19403]]\n",
      "\n",
      "True Negatives: 19394\n",
      "False Positives: 31\n",
      "False Negatives: 75\n",
      "True Positives: 19403\n"
     ]
    }
   ],
   "source": [
    "# MODEL EVALUATION - Training Set\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SET EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "y_train_pred = log_reg_model.predict(train_X_scaled)\n",
    "y_train_proba = log_reg_model.predict_proba(train_X_scaled)\n",
    "\n",
    "train_accuracy = accuracy_score(train_y, y_train_pred)\n",
    "train_precision = precision_score(train_y, y_train_pred)\n",
    "train_recall = recall_score(train_y, y_train_pred)\n",
    "train_f1 = f1_score(train_y, y_train_pred)\n",
    "\n",
    "print(f\"\\nAccuracy:  {train_accuracy:.4f}\")\n",
    "print(f\"Precision: {train_precision:.4f}\")\n",
    "print(f\"Recall:    {train_recall:.4f}\")\n",
    "print(f\"F1-Score:  {train_f1:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix (Training):\")\n",
    "cm_train = confusion_matrix(train_y, y_train_pred)\n",
    "print(cm_train)\n",
    "print(f\"\\nTrue Negatives: {cm_train[0,0]}\")\n",
    "print(f\"False Positives: {cm_train[0,1]}\")\n",
    "print(f\"False Negatives: {cm_train[1,0]}\")\n",
    "print(f\"True Positives: {cm_train[1,1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "169a4ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEST SET EVALUATION\n",
      "============================================================\n",
      "\n",
      "Accuracy:  0.9065\n",
      "Precision: 0.8983\n",
      "Recall:    0.9143\n",
      "F1-Score:  0.9062\n",
      "\n",
      "Confusion Matrix (Test):\n",
      "[[1967  221]\n",
      " [ 183 1952]]\n",
      "\n",
      "True Negatives: 1967\n",
      "False Positives: 221\n",
      "False Negatives: 183\n",
      "True Positives: 1952\n",
      "\n",
      "Detailed Classification Report (Test):\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Not Refusal (0)       0.91      0.90      0.91      2188\n",
      "    Refusal (1)       0.90      0.91      0.91      2135\n",
      "\n",
      "       accuracy                           0.91      4323\n",
      "      macro avg       0.91      0.91      0.91      4323\n",
      "   weighted avg       0.91      0.91      0.91      4323\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MODEL EVALUATION - Test Set\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST SET EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "y_test_pred = log_reg_model.predict(test_X_scaled)\n",
    "y_test_proba = log_reg_model.predict_proba(test_X_scaled)\n",
    "\n",
    "test_accuracy = accuracy_score(test_y, y_test_pred)\n",
    "test_precision = precision_score(test_y, y_test_pred)\n",
    "test_recall = recall_score(test_y, y_test_pred)\n",
    "test_f1 = f1_score(test_y, y_test_pred)\n",
    "\n",
    "print(f\"\\nAccuracy:  {test_accuracy:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall:    {test_recall:.4f}\")\n",
    "print(f\"F1-Score:  {test_f1:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix (Test):\")\n",
    "cm_test = confusion_matrix(test_y, y_test_pred)\n",
    "print(cm_test)\n",
    "print(f\"\\nTrue Negatives: {cm_test[0,0]}\")\n",
    "print(f\"False Positives: {cm_test[0,1]}\")\n",
    "print(f\"False Negatives: {cm_test[1,0]}\")\n",
    "print(f\"True Positives: {cm_test[1,1]}\")\n",
    "\n",
    "print(\"\\nDetailed Classification Report (Test):\")\n",
    "print(classification_report(test_y, y_test_pred, target_names=['Not Refusal (0)', 'Refusal (1)']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
